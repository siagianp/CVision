{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python39\\lib\\site-packages (1.20.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp39-cp39-win_amd64.whl (8.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python39\\lib\\site-packages (from matplotlib) (1.20.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.1.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting cycler>=0.10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: kiwisolver, six, python-dateutil, pyparsing, pillow, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.1.0 pyparsing-2.4.7 python-dateutil-2.8.1 six-1.15.0\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.1-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\python39\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python39\\lib\\site-packages (from pandas) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.2.1 pytz-2021.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "!pip3 install numpy\n",
    "!pip3 install matplotlib\n",
    "!pip3 install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing librarires\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a50c748625fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "#image_classification_part1.ipynb\n",
    "#https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=MLZKVtE0dSfk\n",
    "#https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb\n",
    "\n",
    "#pip3 install fastai==0.7.0\n",
    "import os \n",
    "import zipfile \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "5-v0Jm3e7AxA",
    "outputId": "f2c02736-e273-4932-fd54-fb98e835a5dd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Cat vs. Dog Image Classification\n",
    "#Exercise 1: Building a Convnet from Scratch\n",
    "#Estimated completion time: 20 minutes\n",
    "\n",
    "#In this exercise, we will build a classifier model from scratch that is able to distinguish dogs from cats. We will follow these steps:\n",
    "\n",
    "#Explore the example data\n",
    "#Build a small convnet from scratch to solve our classification problem\n",
    "#Evaluate training and validation accuracy\n",
    "\n",
    "#Explore the Example Data\n",
    "\n",
    "#!wget --no-check-certificate \\\n",
    "#    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "#    -O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import zipfile\n",
    "\n",
    "#local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "#zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "#zip_ref.extractall('/tmp')\n",
    "#zip_ref.close()\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#local_zip = 'cats_and_dogs_filtered.zip'\n",
    "local_zip = 'E:\\Google Colab\\Data_cat_dog\\cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "#zip_ref.extractall('E:\\Google Colab\\Data_cat_dog')\n",
    "zip_ref.extractall('\\Data_cat_dog')\n",
    "\n",
    "#zip_ref.extractall('/tmp')\n",
    "\n",
    "zip_ref.close()\n",
    "\n",
    "#local_add = 'D:\\downloads\\cats_and_dogs_filtered.zip'\n",
    "#zip_ref = zipfile.ZipFile(local_add,'r')\n",
    "#zip_ref.extractall('D:\\downloads')\n",
    "#zip_ref.close()\n",
    "\n",
    "#path = 'D:\\downloads\\cats_and_dogs_filtered'\n",
    "#train_dir = os.path.join(path, 'train')\n",
    "#validation_dir = os.path.join(path, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dog_train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e668fa5a925e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#dog_validation_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#'D:\\\\downloads\\\\cats_and_dogs_filtered\\\\validation\\\\dogs'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_dog_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdog_train_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_cat_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_train_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#https://jovian.ai/lucifersingh31/cats-and-dogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dog_train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "#dog_validation_dir\n",
    "#'D:\\\\downloads\\\\cats_and_dogs_filtered\\\\validation\\\\dogs'\n",
    "train_dog_fname = os.listdir(dog_train_dir)\n",
    "train_cat_fname = os.listdir(cat_train_dir)\n",
    "#https://jovian.ai/lucifersingh31/cats-and-dogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dog_fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-954098edb22a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dog_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cat_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dog_fname' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_dog_fname)\n",
    "len(train_cat_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.101.jpg', 'cat.102.jpg', 'cat.103.jpg', 'cat.104.jpg', 'cat.105.jpg', 'cat.106.jpg']\n",
      "['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.101.jpg', 'dog.102.jpg', 'dog.103.jpg', 'dog.104.jpg', 'dog.105.jpg', 'dog.106.jpg']\n",
      "# of training cat examples:  1000\n",
      "# of training dog examples:  1000\n",
      "# of validation cat examples:  500\n",
      "# of validation dog examples:  500\n"
     ]
    }
   ],
   "source": [
    "# construct addresses for two datasets \n",
    "base_dir = '/data/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "val_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "val_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cats_fnames = os.listdir(train_cats_dir)\n",
    "print(train_cats_fnames[:10])\n",
    "\n",
    "train_dogs_fnames = os.listdir(train_dogs_dir)\n",
    "print(train_dogs_fnames[:10])\n",
    "\n",
    "print('# of training cat examples: ', len(os.listdir(train_cats_dir)))\n",
    "print('# of training dog examples: ', len(os.listdir(train_dogs_dir)))\n",
    "print('# of validation cat examples: ', len(os.listdir(val_cats_dir)))\n",
    "print('# of validation dog examples: ', len(os.listdir(val_dogs_dir)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cat_fnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-121f1f5fb100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m next_cat_pix = [os.path.join(train_cats_dir, fname) \n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_cat_fnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                ]\n\u001b[0;32m     31\u001b[0m next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cat_fnames' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "              for fname in train_cat_fnames[pic_index-8:pic_index]\n",
    "              ]\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "                for fname in train_dog_fnames[pic_index-8:pic_index]\n",
    "              ]\n",
    "\n",
    "        \n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    \n",
    "#next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "              #  for fname in train_cat_fnames[image_index-8:image_index]\n",
    "            #   ]\n",
    "#next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "           #     for fname in train_dog_fnames[image_index-8:image_index]\n",
    "           #    ]\n",
    "\n",
    "\n",
    "#for i, img_path in enumerate(next_cat_pix+next_dog_pic):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    " #   sp = plt.subplot(nrows, ncols, i + 1)\n",
    " #   sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    " #   img = mpimg.imread(img_path)\n",
    " #   plt.imshow(img)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7f223469df20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-432cce5512fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the three color channels: R, G, and B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# First convolution extracts 16 filters that are 3x3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-0c814711189c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Flatten feature map to a 1-dim tensor so we can add fully connected layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a fully connected layer with ReLU activation and 512 hidden units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model:\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
    "# connected layer + sigmoid output layer\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-32d82a65dfc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[0;32m      4\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               metrics=['acc'])\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-91d346d1b720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit_generator(\n\u001b[0m\u001b[0;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 2000 images = batch_size * steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ef7c9d41109e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Let's define a new Model that will take an image as input, and will output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = Model(img_input, successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
    "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0d9a7e98fbad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Retrieve a list of accuracy results on training and validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# sets for each training epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end\n",
    "#https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=651IgjLyo-Jx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a68477818a29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcat_img_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_cats_fnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdog_img_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dogs_fnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cats_fnames]\n",
    "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dogs_fnames]\n",
    "img_path = random.choice(cat_img_files+dog_img_files)\n",
    "img = load_img(img_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-47adc07178d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minception_v3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# non-public APIs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'])(\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e258041368e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# data pre-processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_datagen= ImageDataGenerator(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# normalize pixel values to be between [0,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrotation_range\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwidth_shift_range\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# data pre-processing\n",
    "train_datagen= ImageDataGenerator(\n",
    "    rescale=1./255, # normalize pixel values to be between [0,1]\n",
    "    rotation_range= 40,\n",
    "    width_shift_range= 0.2,\n",
    "    height_shift_range= 0.2,\n",
    "    shear_range= 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip= True)\n",
    "\n",
    "# DO NOT augment the validation set\n",
    "val_datagen= ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(150, 150),\n",
    "    batch_size=128,\n",
    "    class_mode='binary') # binary labels for binary cross entropy loss\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir, \n",
    "    target_size=(150, 150),\n",
    "    batch_size=128,\n",
    "    class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2913ef46efe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# build the CNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 16 3x3 filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# max(0, x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# max pooling with 2x2 window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# build the CNN\n",
    "input_layer = layers.Input(shape=(150, 150, 3))\n",
    "# 16 3x3 filters\n",
    "x = layers.Conv2D(16, 3, activation='relu')(input_layer) # max(0, x)\n",
    "# max pooling with 2x2 window\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "# 32 3x3 filters\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "# max pooling with 2x2 window\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "# 64 3x3\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "# max pooling with 2x2 window\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "# flatten feature map to a 1D tensor \n",
    "x = layers.Flatten()(x)\n",
    "# fully connected layer with relu activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "# add dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# output layer with a signal node and a sigmoid activation, \n",
    "# since we have a binary classification problem\n",
    "output = layers.Dense(1, activation='sigmoid')(x) # [0,1]\n",
    "model = Model(input_layer, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b924abdaeb94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# configurate training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.compile(loss='binary_crossentropy',\n\u001b[0m\u001b[0;32m      3\u001b[0m              \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              metrics=['acc'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# configurate training\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.001),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-801671debc32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=50,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9e2b138142c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# no more overfitting, if we train for longer the accuracy would increase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate result \n",
    "# no more overfitting, if we train for longer the accuracy would increase\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, label='training')\n",
    "plt.plot(epochs, val_acc, label='validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, label='training')\n",
    "plt.plot(epochs, val_loss, label='validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c3e08613a991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdog_img_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dogs_fnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_img_files\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdog_img_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# display the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "# try a couple of concrete examples\n",
    "# pick a random image\n",
    "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cats_fnames]\n",
    "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dogs_fnames]\n",
    "img_path = random.choice(cat_img_files+dog_img_files)\n",
    "img = load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# display the image\n",
    "plt.imshow(img)\n",
    "plt.grid(False)\n",
    "\n",
    "# preprocess image to numpy array and normalize pizels\n",
    "x = img_to_array(img) # numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,)+x.shape) # numpy array with shpae(1, 150, 150, 3)\n",
    "x /= 255 # normalize pixel values to be in the range of [0,1])\n",
    "\n",
    "# predict the category, 1 being dog and 0 being cat\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('cd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tensorflow.js\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates some weight files and a json file containing architectures of the model\n",
    "!mkdir model2\n",
    "!tensorflowjs_converter --input_format keras cd.h5 model2/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the model up\n",
    "!zip -r modelKerasFinal.zip model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move file\n",
    "!mv modelKerasFinal.zip gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://colab.research.google.com/drive/1wRnji3spwaYScgKlElK6OzuSXgLQfA_P#scrollTo=onMRP_DzW2bY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cat_fnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2e2da7a1e3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpic_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m next_cat_pix = [os.path.join(train_cats_dir, fname) \n\u001b[1;32m----> 7\u001b[1;33m                 for fname in train_cat_fnames[pic_index-8:pic_index]]\n\u001b[0m\u001b[0;32m      8\u001b[0m next_dog_pix = [os.path.join(train_dogs_dir, fname) \n\u001b[0;32m      9\u001b[0m                 for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cat_fnames' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "                for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "                for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a Small Convnet from Scratch to Get to 72% Accuracy\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On top of it we stick two fully-connected layers. Because we are facing a two-class classification problem, i.e. a binary classification problem, we will end our network with a sigmoid activation, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0).\n",
    "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create model:\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
    "# connected layer + sigmoid output layer\n",
    "model = Model(img_input, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "#Let's set up data generators that will read pictures in our source folders, convert them to float32 tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of 20 images of size 150x150 and their labels (binary).\n",
    "\n",
    "#As you may already know, data that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) In our case, we will preprocess our images by normalizing the pixel values to be in the [0, 1] range (originally all values are in the [0, 255] range).\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5e22cf9df77b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 validation images. (This may take a few minutes to run.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = model.fit_generator(\n\u001b[0m\u001b[0;32m      4\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 2000 images = batch_size * steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 validation images. (This may take a few minutes to run.)\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Intermediate Representations\n",
    "#To get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.\n",
    "\n",
    "#Let's pick a random cat or dog image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map. Rerun this cell to generate intermediate representations for a variety of training images.\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = Model(img_input, successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
    "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Accuracy and Loss for the Model\n",
    "#Let's plot the training/validation accuracy and loss as collected during training:\n",
    "\n",
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see, we are overfitting like it's getting out of fashion. Our training accuracy (in blue) gets close to 100% (!) while our validation accuracy (in green) stalls as 70%. Our validation loss reaches its minimum after only five epochs.\n",
    "\n",
    "#Clean Up\n",
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "#!apt-get install\n",
    "# # Imports\n",
    "# pip install \n",
    "!conda install pip\n",
    "!conda install matplotlib\n",
    "!pip install matplotlib\n",
    "\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install os\n",
    "!pip install glob\n",
    "!pip install matplotlib-venn\n",
    "!pip install libfluidsynth1\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "\n",
    "# For the latest nightly build:\n",
    "!pip install tf-nightly\n",
    "!pip install graphviz && pip install pydot\n",
    "!pip install pydot\n",
    "!pip install python-cartopy python3-cartopy\n",
    "\n",
    "# For the current version: \n",
    "\n",
    "#!pip install --upgrade tensorflow\n",
    "# For a specific version:\n",
    "#!pip install tensorflow==1.2\n",
    "# To determine which version you're using:\n",
    "#!pip show tensorflow\n",
    "#!pip install tensorflow==2.0.0-beta1\n",
    "#!pip install tensorflow==2.0.0\n",
    "# Upgrade Tensor Flow\n",
    "# To determine which version you're using:\n",
    "!pip show tensorflow\n",
    "# For the current version: \n",
    "!pip install --upgrade tensorflow\n",
    "# For a specific version:\n",
    "!pip install tensorflow==2.6.8\n",
    "# For the latest nightly build:\n",
    "!pip install tf-nightly\n",
    "\t\n",
    " # !pip install Python \n",
    "!pip install Keras==2.1.6 \n",
    "#!pip install TensorFlow==2.6.8\n",
    "!pip install Coremltools  \n",
    "    \n",
    "# https://pypi.python.org/pypi/libarchive\n",
    "        #!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
    "!pip install python-libarchive\n",
    "!git clone https://github.com/libarchive/libarchive\n",
    "import libarchive\n",
    "# https://pypi.python.org/pypi/pydot\n",
    "!pip install graphviz && pip install pydot\n",
    "#!apt-get -qq install -y graphviz && pip install pydot\n",
    "import pydot\n",
    "          #!apt-get -qq install python-cartopy python3-cartopy\n",
    "!pip install python-cartopy python3-cartopy\n",
    "import cartopy\n",
    "\n",
    "!pip install pickle\n",
    "#pip\n",
    "!pip install pickle-mixin\n",
    "\n",
    "#import library\n",
    "import pickle\n",
    "\n",
    "!pip install scipy-0.17.0-cp27-none-win_amd64.whl\n",
    "!pip install --upgrade pip\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install seaborn\n",
    "#run install_lib\n",
    "#!apt-get install -y python3-seaborn\n",
    "#!apt install python-scipy python-pandas\n",
    "\n",
    "!pip install python3-seaborn\n",
    "!pip install python-scipy python-pandas\n",
    "!pip install seaborn\n",
    "import seaborn\n",
    "#python -m pip install \n",
    "!pip install matplotlib\n",
    "!pip install -U scikit-learn\n",
    "#python -m pip show scikit-learn # to see which version and where scikit-learn is installedpython -m pip freeze # to see all packages installed in the active virtualenvpython -c \"import sklearn; sklearn.show_versions()\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageatm\n",
      "  Downloading imageatm-0.1.1-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (4.54.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (0.23.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from imageatm) (2.10.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (8.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (3.3.3)\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.18.217-py2.py3-none-any.whl (3.5 MB)\n",
      "Requirement already satisfied: PyYAML<5.4,>=3.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from awscli->imageatm) (5.3.1)\n",
      "Collecting botocore==1.19.57\n",
      "  Downloading botocore-1.19.57-py2.py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from botocore==1.19.57->awscli->imageatm) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore==1.19.57->awscli->imageatm) (2.8.1)\n",
      "Collecting Click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting colorama<0.4.4,>=0.2.5\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting Keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: PyYAML<5.4,>=3.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from awscli->imageatm) (5.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from imageatm) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from Keras==2.2.4->imageatm) (1.1.2)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from imageatm) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Collecting keras-vis>=0.4.1\n",
      "  Downloading keras_vis-0.4.1-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from imageatm) (2.10.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (3.3.3)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore==1.19.57->awscli->imageatm) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->imageatm) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->imageatm) (2.4.7)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->imageatm) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting papermill\n",
      "  Downloading papermill-2.3.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from papermill->imageatm) (0.3)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from papermill->imageatm) (0.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (4.54.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from papermill->imageatm) (2.25.0)\n",
      "Requirement already satisfied: PyYAML<5.4,>=3.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from awscli->imageatm) (5.3.1)\n",
      "Requirement already satisfied: nbformat in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from papermill->imageatm) (5.0.8)\n",
      "Collecting ansiwrap\n",
      "  Downloading ansiwrap-0.8.4-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting black\n",
      "  Downloading black-20.8b1.tar.gz (1.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from black->papermill->imageatm) (3.7.4.3)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (1.4.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (6.1.7)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (5.0.5)\n",
      "Requirement already satisfied: nbformat in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from papermill->imageatm) (5.0.8)\n",
      "Requirement already satisfied: async-generator in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (1.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore==1.19.57->awscli->imageatm) (2.8.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (5.0.5)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->imageatm) (6.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->imageatm) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->imageatm) (19.0.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (5.0.5)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->imageatm) (228)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbformat->papermill->imageatm) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient>=0.2.0->papermill->imageatm) (5.0.5)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->imageatm) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbformat->papermill->imageatm) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (20.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (50.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (3.4.0)\n",
      "Collecting pathspec<1,>=0.6\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting regex>=2020.1.8\n",
      "  Downloading regex-2020.11.13-cp37-cp37m-win_amd64.whl (269 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->papermill->imageatm) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from botocore==1.19.57->awscli->imageatm) (1.26.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->papermill->imageatm) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->papermill->imageatm) (2.10)\n",
      "Collecting rsa<=4.5.0,>=3.1.2\n",
      "  Downloading rsa-4.5-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from rsa<=4.5.0,>=3.1.2->awscli->imageatm) (0.4.8)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.4-py2.py3-none-any.whl (69 kB)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.18.1-cp37-cp37m-win_amd64.whl (12.1 MB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (3.3.3)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from imageatm) (8.0.1)\n",
      "Collecting networkx>=2.0\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from networkx>=2.0->scikit-image->keras-vis>=0.4.1->imageatm) (4.4.2)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp37-cp37m-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->imageatm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->imageatm) (0.17.0)\n",
      "Collecting scipy==1.1.*\n",
      "  Downloading scipy-1.1.0-cp37-none-win_amd64.whl (30.9 MB)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Collecting tenacity\n",
      "  Downloading tenacity-6.3.1-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp37-cp37m-win_amd64.whl (63.1 MB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow==1.13.1->imageatm) (1.32.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (3.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.36.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from Keras==2.2.4->imageatm) (1.1.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.36.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->imageatm) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->imageatm) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow==1.13.1->imageatm) (1.32.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.3.1 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow-gpu 2.3.1 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.4 which is incompatible.\n",
      "tensorflow-gpu 2.3.1 requires tensorboard<3,>=2.3.0, but you have tensorboard 1.13.1 which is incompatible.\n",
      "metrics 0.3.3 requires pathspec==0.5.5, but you have pathspec 0.8.1 which is incompatible.\n",
      "metrics 0.3.3 requires Pygments==2.2.0, but you have pygments 2.7.2 which is incompatible.\n",
      "WARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\user\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->papermill->imageatm) (3.1.1)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.13.1->imageatm) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.15.0)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting textwrap3>=0.9.2\n",
      "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.1.14-py3-none-any.whl (158 kB)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from h5py->imageatm) (1.19.4)\n",
      "Collecting toml>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbformat->papermill->imageatm) (0.2.0)\n",
      "Collecting typed-ast>=1.4.0\n",
      "  Downloading typed_ast-1.4.2-cp37-cp37m-win_amd64.whl (155 kB)\n",
      "Collecting yarl\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->papermill->imageatm) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from black->papermill->imageatm) (3.7.4.3)\n",
      "Collecting multidict>=4.0\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-win_amd64.whl (48 kB)\n",
      "Building wheels for collected packages: black\n",
      "  Building wheel for black (PEP 517): started\n",
      "  Building wheel for black (PEP 517): finished with status 'done'\n",
      "  Created wheel for black: filename=black-20.8b1-py3-none-any.whl size=124186 sha256=61fd5bc9febde22f7fafe448cb9e0d3ab31d016d7ee4584c2d2d771e825bf161\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\c5\\85\\79\\f3af8daaf8037c0bf14beb3b7a1511a39b6e6902ca2aaf494e\n",
      "Successfully built black\n",
      "Installing collected packages: jmespath, typed-ast, toml, tifffile, textwrap3, scipy, regex, PyWavelets, pathspec, networkx, mypy-extensions, mock, keras-applications, imageio, Click, botocore, appdirs, tensorflow-estimator, tensorboard, tenacity, scikit-image, s3transfer, rsa, multidict, Keras, docutils, colorama, black, astor, ansiwrap, yarl, tensorflow, papermill, keras-vis, awscli, imageatm\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "  Attempting uninstall: pathspec\n",
      "    Found existing installation: pathspec 0.5.5\n",
      "    Uninstalling pathspec-0.5.5:\n",
      "      Successfully uninstalled pathspec-0.5.5\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.6\n",
      "    Uninstalling rsa-4.6:\n",
      "      Successfully uninstalled rsa-4.6\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.3.1\n",
      "    Uninstalling tensorflow-2.3.1:\n",
      "      Successfully uninstalled tensorflow-2.3.1\n",
      "Successfully installed Click-7.1.2 Keras-2.2.4 PyWavelets-1.1.1 ansiwrap-0.8.4 appdirs-1.4.4 astor-0.8.1 awscli-1.18.217 black-20.8b1 botocore-1.19.57 colorama-0.4.3 docutils-0.15.2 imageatm-0.1.1 imageio-2.9.0 jmespath-0.10.0 keras-applications-1.0.8 keras-vis-0.4.1 mock-4.0.3 multidict-5.1.0 mypy-extensions-0.4.3 networkx-2.5 papermill-2.3.0 pathspec-0.8.1 regex-2020.11.13 rsa-4.6 s3transfer-0.3.4 scikit-image-0.18.1 scipy-1.1.0 tenacity-6.3.1 tensorboard-2.3.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 textwrap3-0.9.2 tifffile-2021.1.14 toml-0.10.2 typed-ast-1.4.2 yarl-1.6.3\n"
     ]
    }
   ],
   "source": [
    "#https://colab.research.google.com/github/idealo/imageatm/blob/master/examples/imageatm_cats_and_dogs.ipynb#scrollTo=ECK98OAuSQkc\n",
    "# install imageatm via PyPi\n",
    "!pip3 install imageatm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a6DieCWY77qa"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-4-3d435e7825ec>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-3d435e7825ec>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    E:\\Google Colab\\Classify\\cats_and_dogs_filtered.zip \\-O cats_and_dogs_filtered.zip\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# Load Data \n",
    "# download cats and dogs dataset\n",
    "\n",
    "#!wget --no-check-certificate \\\n",
    "   # https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    # -O cats_and_dogs_filtered.zip\n",
    "    \n",
    "      \n",
    "#E:\\Google Colab\\Classify\\cats_and_dogs_filtered.zip \\-O cats_and_dogs_filtered.zip\n",
    "\n",
    "\n",
    "    \n",
    "#Dataset_Train = pd.read_csv('E:/Google Colab/SAR_v2.3/SAR_v2.3_raw_all_xy.csv')\n",
    "#Dataset_Test = pd.read_csv('E:/Google Colab/SAR_v2.3/SAR_v2.3_raw_test1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cat Dog Filtered Keras Functional.ipynb\n",
    "#https://colab.research.google.com/drive/1wRnji3spwaYScgKlElK6OzuSXgLQfA_P\n",
    "#https://colab.research.google.com/drive/1wRnji3spwaYScgKlElK6OzuSXgLQfA_P\n",
    "\n",
    "#C:\\Users\\User\\data\n",
    "\n",
    "# unzip downloaded file\n",
    "local_zip = 'cats_and_dogs_filtered.zip'\n",
    "\n",
    "\n",
    "\n",
    "#local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-849f96f6be30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# base_dir = '/tmp/cats_and_dogs_filtered'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvalidation_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# construct addresses for two datasets \n",
    "# base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "# base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "val_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "val_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cats_fnames = os.listdir(train_cats_dir)\n",
    "print(train_cats_fnames[:10])\n",
    "\n",
    "train_dogs_fnames = os.listdir(train_dogs_dir)\n",
    "print(train_dogs_fnames[:10])\n",
    "\n",
    "print('# of training cat examples: ', len(os.listdir(train_cats_dir)))\n",
    "print('# of training dog examples: ', len(os.listdir(train_dogs_dir)))\n",
    "print('# of validation cat examples: ', len(os.listdir(val_cats_dir)))\n",
    "print('# of validation dog examples: ', len(os.listdir(val_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5366a468444b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDataset_Train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/Google Colab/SAR_v2.3/SAR_v2.3_raw_all_xy.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDataset_Train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "Dataset_Train = pd.read_csv(\"E:/Google Colab/SAR_v2.3/SAR_v2.3_raw_all_xy.csv\")\n",
    "Dataset_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Test = pd.read_csv(\"E:/Google Colab/SAR_v2.3/SAR_v2.3_raw_test.csv\")\n",
    "Dataset_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bhimmetoglu/time-series-medicine/blob/master/HAR/HAR-LSTM.ipynb\n",
    "# https://github.com/bhimmetoglu/time-series-medicine/blob/master/HAR/HAR-LSTM.ipynb\n",
    "#utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA-AHaFRMYN3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 2 load Data\n",
    "#import libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"E:\\Google Colab\\SAR_v2.3\"\n",
    "read_files = glob.glob(os.path.join(files_path,\"*.csv\"))\n",
    "\n",
    "np_array_values = []\n",
    "for files in read_files:\n",
    "    employee_data = pd.read_csv(files, header=0)\n",
    "    np_array_values.append(employee_data)\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 3 load Data\n",
    "#https://machinelearningmastery.com/how-to-load-and-explore-a-standard-human-activity-recognition-problem/\n",
    "\n",
    "# load sequence for each subject, returns a list of numpy arrays\n",
    "def load_dataset(prefix=''):\n",
    "\tsubjects = list()\n",
    "\tdirectory = prefix + 'HAR/'\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\tif not filename.endswith('.csv'):\n",
    "\t\t\tcontinue\n",
    "\t\tdf = read_csv(filename, header=None)\n",
    "\t\t# drop row number\n",
    "\t\tvalues = df.values[:, 1:]\n",
    "\t\tsubjects.append(values)\n",
    "\treturn subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The complete example is listed below\n",
    "# load dataset\n",
    "from os import listdir\n",
    "from pandas import read_csv\n",
    " \n",
    "# load sequence for each subject, returns a list of numpy arrays\n",
    "def load_dataset(prefix=''):\n",
    "\tsubjects = list()\n",
    "\tdirectory = prefix + 'HAR/'\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\tif not filename.endswith('.csv'):\n",
    "\t\t\tcontinue\n",
    "\t\tdf = read_csv(filename, header=None)\n",
    "\t\t# drop row number\n",
    "\t\tvalues = df.values[:, 1:]\n",
    "\t\tsubjects.append(values)\n",
    "\treturn subjects\n",
    " \n",
    "# load\n",
    "subjects = load_dataset()\n",
    "print('Loaded %d subjects' % len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 4 load Data\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "#https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io/blob/master/Machine%20Learning%20Part.ipynb\n",
    "    \n",
    "# Import default_timer to compute durations\n",
    "from timeit import default_timer as timer\n",
    "Debut=timer() # start time\n",
    "\n",
    "import numpy as np # import numpy library\n",
    "import pandas as pd # importing pandas library\n",
    "\n",
    "# scrapping file paths\n",
    "from glob import glob\n",
    "\n",
    "# Allows the use of display() for DataFrames\n",
    "from IPython.display import display \n",
    "\n",
    "from matplotlib import pyplot as plt # import matplot. pyplot to allow figure's plotting\n",
    "#plt.style.use('bmh') # for better plots    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 5 load Data\n",
    "# scrapping data files path\n",
    "#DF_paths_list=sorted(glob(\"Data/New-Data/full_Datasets_type_I_and_II/*\"))\n",
    "DF_paths_list=sorted(glob(\"E:/Google Colab/SAR_v2.3/*\"))\n",
    "\n",
    "display(DF_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I # Importing Dataset\n",
    "#https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io/blob/master/Machine%20Learning%20Part.ipynb\n",
    "# https://github.com/anas337/Human-Activity-Recognition-Using-Smartphones.github.io/blob/master/.ipynb_checkpoints/signal%20processing%20pipeline-checkpoint.ipynb\n",
    "# loading datasets(these datasets are the outputs of the signal processing pipeline )\n",
    "#Dataset_type_I_part1 = pd.read_csv('Data/New-Data/full_Datasets_type_I_and_II\\\\Dataset_I_part1.csv')\n",
    "#Dataset_type_I_part2 = pd.read_csv('Data/New-Data/full_Datasets_type_I_and_II\\\\Dataset_I_part2.csv')\n",
    "#Dataset_type_II_part1= pd.read_csv('Data/New-Data/full_Datasets_type_I_and_II\\\\Dataset_II_part1.csv')\n",
    "#Dataset_type_II_part2= pd.read_csv('Data/New-Data/full_Datasets_type_I_and_II\\\\Dataset_II_part2.csv')\n",
    "\n",
    "Dataset_Train = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv')\n",
    "Dataset_Test = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv')\n",
    "\n",
    "# select parts two be conctenated\n",
    "#frames_I=[Dataset_type_I_part1,Dataset_type_I_part2]\n",
    "#frames_II=[Dataset_type_II_part1,Dataset_type_II_part2]\n",
    "\n",
    "frames_Train =[Dataset_Train]\n",
    "frames_Test =[Dataset_Test]\n",
    "\n",
    "# concatenate each dataframes' parts\n",
    "#Dataset_type_I=pd.concat(frames_I)\n",
    "#Dataset_type_II=pd.concat(frames_II)\n",
    "\n",
    "Dataset_Train=pd.concat(frames_Train)\n",
    "Dataset_Test=pd.concat(frames_Test)\n",
    "\n",
    "# index reset\n",
    "#Dataset_type_I.reset_index(level=0, drop=True, inplace=True)\n",
    "#Dataset_type_II.reset_index(level=0, drop=True, inplace=True)\n",
    "Dataset_Train.reset_index(level=0, drop=True, inplace=True)\n",
    "Dataset_Test.reset_index(level=0, drop=True, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# II # Datasets Exploration and Exploratory Visualizations\n",
    "\n",
    "# II # 1 # Datapoints number per each tuple (user,activity) function\n",
    "\n",
    "# This function returns a table includes the number of \n",
    "# windows per each tuple(user_id , activity id) included in the dataset \n",
    "\n",
    "def num_row_user_act(Df):\n",
    "    \n",
    "    user_Ids=sorted(Df['user_Id'].unique()) # extracting and sorting unqiue user ids \n",
    "    activity_Ids=sorted(Df['activity_Id'].unique()) # extracting and sorting unqiue activity ids \n",
    "    act_columns=['Activity '+str(int(Id)) for Id in activity_Ids ] # defining column names used in output table\n",
    "    \n",
    "    if len(activity_Ids)==7: # adapting column names in case the function deals with dataset type III\n",
    "        act_columns=act_columns[0:6]+['P_Transitions'] \n",
    "    \n",
    "    users_index=['User '+ str(int(Id)) for Id in user_Ids] # defining rows names used in output table\n",
    "    \n",
    "    # counting the number of windows per each tuple(user_id,activity_id)\n",
    "    # store these values in 2D numpy array\n",
    "    data=np.array([ [len(Df[(Df[\"user_Id\"]== user_ID) &(Df[\"activity_Id\"]==activity_ID)]) \n",
    "               for activity_ID in activity_Ids ] for user_ID in user_Ids])\n",
    "    \n",
    "    # Create a pandas dataframe from the array above\n",
    "    win_per_act_per_user=pd.DataFrame(data = data,columns=act_columns,index=users_index)\n",
    "    \n",
    "    \n",
    "    return win_per_act_per_user # returns the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# II # 2 # Visualizing Activities Distribution\n",
    "# This function returns the weights activity and visualize the distribution of a column\n",
    "# This function will be applied only to target columns\n",
    "def visualize_column(Df,column):\n",
    "    \n",
    "    labels= sorted(Df[column].unique()) # extracting and sorting activity unique ids\n",
    "    Als_dict={ key: len(Df[Df[column]==key]) for key in labels} # counting the number of windows per activity\n",
    "    data=[Als_dict[key] for key in labels] # sorting these numbers\n",
    "    \n",
    "    weights=np.array(data)/float(np.array(data).sum()) # calculating weights of each activity\n",
    "    \n",
    "    columns=[\"Activity \"+str(int(key)) for key in labels] # defining columns of weights' table\n",
    "    \n",
    "    Df_weights=pd.DataFrame(data=None,columns=columns)# defining an empty dataframe with column names\n",
    "    Df_weights.loc['Weights']=weights # appending weights row\n",
    "    \n",
    "    print(\"_____ The weights of each activity _____\")\n",
    "    display(Df_weights) # displying weights table\n",
    "    print(\"\")\n",
    "    plt.bar(columns,data) # ploting activity distribution\n",
    "    plt.xlabel('Activity Labels') # set X axis info\n",
    "    plt.ylabel('Number of Data points') # set Y axis info\n",
    "    plt.title('Number of Data points per activity') # set the figure's title\n",
    "    plt.show() # showing the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# III # Data Exploration PipeLine\n",
    "def data_exploration_pipeline(Dataset,typ,outliers):\n",
    "    # inputs:\n",
    "    #        Dataset: a pandas dataframe can be a full dataset (Train), \n",
    "    #               cleaned dataset(Train, Test), outliers dataset (Train, Test)\n",
    "    \n",
    "    #        typ    : integer type of the dataset possible values: 1(for dataset Train, Test), \n",
    "    #        outliers: Boolean if true dataset we are dealing with is an outlier dataset(contain outlier values)         \n",
    "    \n",
    "    # columns names of the dataset\n",
    "    columns=Dataset.columns\n",
    "    \n",
    "    if not outliers:  # in case we are not dealing with outliers datasets  \n",
    "        # Adapting the dataset name switch the typ\n",
    "        if typ==1:\n",
    "            Dataset_name=\"Dataset_Train \"\n",
    "        if typ==2:\n",
    "            Dataset_name=\"Dataset_Test \"\n",
    "       \n",
    "    else:# in case we are dealing with outliers\n",
    "        \n",
    "        # adapting the dataset names switch the case\n",
    "        if typ==1:\n",
    "            Dataset_name=\"Outliers of Dataset_Train \"\n",
    "        if typ==2:\n",
    "            Dataset_name=\"Outliers of Dataset_Test \"\n",
    "    \n",
    "    # general info about the dataset: number of rows and columns\n",
    "    print(  Dataset_name+'has a shape of: '+ str(Dataset.shape[0]) +' rows and '+str(Dataset.shape[1])+' columns')\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    \n",
    "    if not outliers: # in case dataset is not an outlier dataset\n",
    "        print(\"The first 3 rows of \"+Dataset_name +\":\")\n",
    "        display(Dataset.iloc[0:3]) # display the first 3 rows\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"rows 500, 501, 502 of \"+Dataset_name +\":\")\n",
    "        display(Dataset.iloc[500:503]) # display rows 500,501 and 502\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"Description of the 10 first features:\")\n",
    "        display(Dataset.describe()[columns[0:10]]) # statistics of the first ten time domain features\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"Description of the 10 first frequency features:\")\n",
    "        display(Dataset.describe()[columns[265:275]]) # statistics of the first ten frequency domain features\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "    Stats= num_row_user_act(Dataset)# generate number of windows per each tuple (user,activity)\n",
    "    print(\"Number of windows per user and per each activity:\")\n",
    "    display(Stats)# display the table\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    print(\"Statistics of table above:\")\n",
    "    display(Stats.describe())# table's statics\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    visualize_column(Dataset,\"activity_Id\") # visualize activity distribution of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the data_exploration_pipeline to dataset type 1\n",
    "data_exploration_pipeline(Dataset_Train,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the data_exploration_pipeline to dataset type 1\n",
    "data_exploration_pipeline(Dataset_Test,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# III # Data Preprocessing\n",
    "\n",
    "# III.1 Handling Outliers\n",
    "#####################################################################################\n",
    "def extract_drop_outliers(Df,threshold,typ):\n",
    "    #Df: pandas dataframe (Dataset type I or Dataset type II)\n",
    "    # Threshold: integer : if the number of features detected as ouliers in row exceeds the threshold \n",
    "    #                      therow will be considered as \"outlier row\"\n",
    "    \n",
    "    max_range=len(Df[\"activity_Id\"].unique()) # number of unique activities in Df\n",
    "    \n",
    "    columns=Df.columns # column names of the dataset\n",
    "    \n",
    "    outliers={} # dictionary will contain number of outliers per row . keys are rows' indexes\n",
    "    for i in range(1,max_range+1):# iterate throw each activity type in the dataset\n",
    "        \n",
    "        Df_A=Df[Df['activity_Id']==i] # select rows related to this activity\n",
    "        \n",
    "        for column in columns[:-2]:# iterate throw features columns only in Df_A\n",
    "            \n",
    "            q1= Df_A[column].describe()['25%'] # the value of the first quartile of a column in Df_A\n",
    "            \n",
    "            q3= Df_A[column].describe()['75%'] # the value of the third quartile of a column in Df_A\n",
    "            \n",
    "            low_threshold=q1-1.5*(q3-q1) # define low threshold to detect bottom outliers of a column\n",
    "            high_threshold=q3+1.5*(q3-q1) # define high threshold to detect top outliers of a column\n",
    "            \n",
    "            for e in Df_A.index :# iterate throw Df_A indexes\n",
    "                \n",
    "                if (Df[column].iloc[e]>high_threshold or Df[column].iloc[e]<low_threshold) :# if value is an outlier\n",
    "                    \n",
    "                    if e in outliers.keys(): # if the row index is alread exist in outliers dictionary\n",
    "                        outliers[e]=outliers[e]+1 # increse the number of ouliers for this row\n",
    "                    else:# if the row index does not exist yet in  outliers dic keys\n",
    "                        outliers[e]=1 # add the key with outlier number =1\n",
    "    \n",
    "    indexs=np.array(sorted(outliers.keys())) # rows indexes contain outlier values sorted from low to high\n",
    "    values=np.array([outliers[indexs[i]] for i in range(len(indexs))]) # number of outliers related to each row\n",
    "\n",
    "    indexs_droped=indexs[values>threshold]# store indexes having number of outliers exceeding the threshold in a list\n",
    "    \n",
    "    # Build outliers dataframe using row's indexes\n",
    "    outliers_data=np.array([list(Df.iloc[indexs_droped[i]]) for i in range(len(indexs_droped))])\n",
    "    outliers_Df= pd.DataFrame(data=outliers_data,columns= columns)\n",
    "    \n",
    "    # generate the clean dataframe by droping outliers from the original dataframe\n",
    "    clean_Df=Df.drop(indexs_droped,0,)\n",
    "    \n",
    "    # adapting the name of the dataset switch the case\n",
    "    if typ==1:\n",
    "        dataset_name='Dataset_Train'\n",
    "    if typ==2:\n",
    "        dataset_name=\"Dataset_Test\"\n",
    "    \n",
    "    #### report\n",
    "    print(\"\")\n",
    "    print(\"_______________________________ Original Data Frame info...____________________________________\")\n",
    "    print('Number of rows in the original dataframe '+dataset_name+':',len(Df) ) # original dataset lenght\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df,'activity_Id') # activity distribution of the original dataset\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"________________________________ Outliers info...________________________________________________\")\n",
    "    print(\"A row is considered as outlier if the number of its outliers exceeds: \"+str(threshold)) # threshold info\n",
    "    print('Number of rows droped :',len(indexs_droped) ) # number of rows considered as outliers\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    data_exploration_pipeline(outliers_Df,typ,True) # Apply the data exploration pipeline to outliers dataframe\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print (\"________________________________ Cleaned+\" +dataset_name+\" Dataframe info...________________________________________\")\n",
    "    print ('Number of rows in the clean dataframe '+dataset_name+':',len(clean_Df)) # clean dataframe info\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    data_exploration_pipeline(clean_Df,typ,False)# apply the data exploration pipeline to the clean dataframe\n",
    "    return clean_Df # return the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply extract drop outliers to dataset type I\n",
    "clean_Dataset_Test = extract_drop_outliers(Dataset_Test,100,1)# store the clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply drop extract outliers to dataset type\n",
    "clean_Dataset_Train = extract_drop_outliers(Dataset_Train,100,2)# store the clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# III.2 Features Scaling\n",
    "#################################################################################\n",
    "def scaling_array(oneD_signal):\n",
    "    # inputs: 1D numpy array (one column)\n",
    "    maximum=oneD_signal.max() # maximum of the column\n",
    "    minimum=oneD_signal.min() # min value of the column\n",
    "    Difference=float(maximum-minimum) # max-min\n",
    "    # scaling formula: 2 * (x_i-minimum)/(maximum -minimum)\n",
    "    # apply the scaling formula to each value in the column\n",
    "    scaled_signal=np.array([((float(oneD_signal[i])-minimum)/float(Difference))*2 -1 for i in range(len(oneD_signal))])\n",
    "    \n",
    "    #return the scaled array\n",
    "    return scaled_signal\n",
    "\n",
    "def scaling_DF(data_frame):\n",
    "    # input : pandas dataframe (clean datasets type I or II)\n",
    "    columns=data_frame.columns# column names\n",
    "    # apply the scaling function to each feature columns only\n",
    "    scaled_array=np.apply_along_axis(scaling_array,0,np.array(data_frame[columns[:-2]]))\n",
    "    \n",
    "    # buid the scaled dataset\n",
    "    scaled_df=pd.DataFrame(data=scaled_array,columns=columns[:-2])\n",
    "    \n",
    "    # the user and activity ids columns\n",
    "    scaled_df['activity_Id']=np.array(data_frame['activity_Id'])\n",
    "    scaled_df['user_Id']=np.array(data_frame['user_Id'])\n",
    "    \n",
    "    return scaled_df # return the scaled dataset\n",
    "\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the scaling function to cleaned dataset type I\n",
    "scaled_type_I=scaling_DF(clean_Dataset_type_I)\n",
    "\n",
    "# explore the scaled dataset type I\n",
    "data_exploration_pipeline(scaled_type_I,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the scaling function to cleaned dataset \n",
    "scaled_Train=scaling_DF(clean_Dataset_Train)\n",
    "\n",
    "# explore the scaled dataset \n",
    "data_exploration_pipeline(scaled_Train,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI Dataset \n",
    "# VI.1 Data set Generation\n",
    "act_labels=list(scaled_type_II['activity_Id']) # extract activity labels from scaled type II (ids from 1 to 12)\n",
    "\n",
    "for i in range(len(act_labels)):# iterate throw each activity label\n",
    "    \n",
    "    if act_labels[i]>6: # if activity label belongs to postural transitions ids from 7 to 12\n",
    "        act_labels[i]=7 # the target will be replaced by the id=7 (postural transition)\n",
    "\n",
    "# build dataset type III by replacing the activity id column by the new column create above\n",
    "scaled_Train=pd.DataFrame(data=np.array(scaled_type_II),columns=scaled_type_II.columns)\n",
    "scaled_Train['activity_Id']=np.array(act_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI.2 Exploration\n",
    "# apply the data exploration pipeline to scaled dataset \n",
    "data_exploration_pipeline(scaled_Train,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V. Train-Test Datasets\n",
    "# V.1. Train-Test Datasets creation\n",
    "# Unique Users Ids used for training and testing\n",
    "\n",
    "# volunteersids used for training\n",
    "Train_users =[1,3,5,6,7,8,10,11,14,15,27,17,21,29,30,16,19,20,22,23,25,]\n",
    "\n",
    "#{\"21\" , \"17\", \"29\", \"13\" , \"21\" , \"27\" , \"6\" , \"15\" , \"12\" , \"36\" , \"10\" , \"35\" , \"11\" , \"16\" , \"5\", \"21\" , \"28\" , \"26\" , \"14\" , \"24\" , \"9\" , \"23\" , \"4\" , \"30\" , \"34\" , \"8\" , \"31\" , \"21\" , \"3\" , \"11\" , \"1\" , \"25\" , \"9\" , \"2\" , \"7\" , \"19\"} \n",
    "\n",
    "# volunteers ids used for testing\n",
    "Test_users = [2,4,9,12,13,26,18,28,24,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and test datasets\n",
    "def create_training_testing_data(scaled_Df,train_users,test_users,typ):\n",
    "    # inputs:\n",
    "    #        scaled_DF : pandas dataframe already scaled\n",
    "    #       train_users: list of integers contains train user ids \n",
    "    #       train_users: list of integers contains test user ids \n",
    "    #       typ        : integer from 1 to 3 (depending on the dataset type)\n",
    "    \n",
    "    # select rows related to train users ids store them in numpy array\n",
    "    array_train =np.array([np.array(scaled_Df.iloc[i]) \n",
    "                           for i in range(len(scaled_Df)) if int(scaled_Df['user_Id'].iloc[i]) in train_users])\n",
    "    # select rows related to test users ids store them in numpy array\n",
    "    array_test  =np.array([np.array(scaled_Df.iloc[i]) \n",
    "                           for i in range(len(scaled_Df)) if int(scaled_Df['user_Id'].iloc[i]) in test_users])\n",
    "    \n",
    "    # columns names\n",
    "    columns=scaled_Df.columns\n",
    "    \n",
    "    # build train and test dataframes from numpy arrays above\n",
    "    Df_train= pd.DataFrame(data= array_train,columns=columns)\n",
    "    Df_test = pd.DataFrame(data= array_test,columns=columns)\n",
    "    \n",
    "    \n",
    "    # train features dataframe\n",
    "    Df_train_features= Df_train[columns[:-2]]\n",
    "    # train labels dataframe\n",
    "    Df_train_labels  = Df_train[columns[-2:-1]]\n",
    "    # train user id labels dataframe\n",
    "    Df_train_users   = Df_train[columns[-1]]\n",
    "    \n",
    "    # test features dataframe\n",
    "    Df_test_features= Df_test[columns[:-2]]\n",
    "    # test labels dataframe\n",
    "    Df_test_labels  = Df_test[columns[-2:-1]]\n",
    "    # test user id labels dataframe\n",
    "    Df_test_users   = Df_test[columns[-1]]\n",
    "    \n",
    "    # 2D numpy array : train features\n",
    "    X_train =np.array(Df_train_features)\n",
    "    \n",
    "    # 2D numpy array : test features\n",
    "    X_test  =np.array(Df_test_features)\n",
    "    \n",
    "    # 1D numpy array : train labels\n",
    "    y_train= np.array(Df_train_labels['activity_Id'])\n",
    "    \n",
    "    # 1D numpy array : test labels\n",
    "    y_test = np.array(Df_test_labels ['activity_Id'])\n",
    "    \n",
    "    # adapting the dataset name switch the case\n",
    "    if typ==1:\n",
    "           Dataset_name=\"Dataset_Train\"\n",
    "    if typ==2:\n",
    "           Dataset_name=\"Dataset_Test\"\n",
    "   \n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"______________________________\"+Dataset_name+\" Train features & labels info:______________________________________\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df_train,'activity_Id')# visualize activity distribution of train dataframe\n",
    "    print(\"\")\n",
    "    print(\"______________________________Test features & labels info:______________________________________\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df_test,'activity_Id') # visualize the activity distribution of the test dataframe\n",
    "    \n",
    "    return  [X_train, X_test, y_train, y_test] # return train and test numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary will contain train and test files of each dataframe type\n",
    "train_test_files_dic={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply create_training_testing_data to scaled dataset type I\n",
    "[X_1_train, X_1_test, y_1_train, y_1_test] = create_training_testing_data(scaled_type_I,train_users,test_users,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train test files type I in the dictionary \n",
    "train_test_files_dic[1]=[X_1_train, X_1_test, y_1_train, y_1_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply create_training_testing_data to scaled dataset \n",
    "[X_2_train, X_2_test, y_2_train, y_2_test] = create_training_testing_data(scaled_type_II,train_users,test_users,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train test files type II in the dictionary \n",
    "train_test_files_dic[2]= [X_2_train, X_2_test, y_2_train, y_2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply create_training_testing_data to scaled dataset \n",
    "[X_3_train, X_3_test, y_3_train, y_3_test] = create_training_testing_data(scaled_type_III,train_users,test_users,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI. Train-Test PipeLine\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB as NB # import gaussian naive bayes classifier\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression as LR # import logistic regression classifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score as accuracy # import accuracy score\n",
    "from sklearn.metrics import confusion_matrix as cm # import confusion matrix\n",
    "\n",
    "# intialize models\n",
    "Benchmark_model =NB()\n",
    "Clf1=DTC(random_state=337)\n",
    "Clf2=LR(random_state=337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the adpted confusion matrix\n",
    "def full_confusion_matrix(Df): \n",
    "    # input: \n",
    "    #   Df : pandas dataframe, the contingency table resulted from the confusion matrix defined earlier as cm\n",
    "    \n",
    "    columns=Df.columns # activity names\n",
    "    # add new columns containing detailed scores\n",
    "    new_columns=list(columns)+['data points number','precision %','sensitivity %','specificity %']\n",
    "    \n",
    "    # create the index from the same old columns add an other row called total\n",
    "    new_index=list(columns)+['Total']\n",
    "    \n",
    "    # intialize the confustion matrix dataframe\n",
    "    new_Df=pd.DataFrame(data=None,columns=new_columns, index= new_index)\n",
    "    # intilize values\n",
    "    total_TP=0 # sum of true positives\n",
    "    total_FN=0 # sum of false negatives\n",
    "    total_data_points_number=0 # total number of datapoints\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        TP=Df.loc[column][column] # extract true postives from the contingency table\n",
    "        FN=Df.loc[column].sum()-TP # calculate FN(false negatives)\n",
    "        FP=Df[column].sum()-TP # calculate FP(false positives)\n",
    "        TN=(Df.sum()).sum()-TP-FN-FP # calculate TN(true negatives)\n",
    "        class_data_points=TP+FN  # number of datapoints per activity\n",
    "        # precision score in %\n",
    "        precision= TP/float(TP+FP) * 100\n",
    "        # Recall or sensitivity in %\n",
    "        sensitivity= TP/float(TP+FN) *100\n",
    "        # sepecificity score in %\n",
    "        specificity=TN/float(TN+FP) * 100\n",
    "        \n",
    "        new_row =list(Df.loc[column])+[class_data_points,precision,sensitivity,specificity]# contenate new scores in one row\n",
    "        new_Df.loc[column]=new_row # append the row to the dataframe\n",
    "        \n",
    "        # update intialized values\n",
    "        total_data_points_number= total_data_points_number+class_data_points \n",
    "        total_TP=total_TP+TP\n",
    "        total_FN=total_FN+FN\n",
    "    \n",
    "    # after iterting throw all activity types\n",
    "    # the general accuracy of the model is:\n",
    "    total_accuracy= total_TP/float(total_TP+total_FN) * 100\n",
    "    \n",
    "    # add total values to the dataframe\n",
    "    new_Df.loc['Total'] [['data points number','precision %','sensitivity %','specificity %']]=['data points number='+str(total_data_points_number),'','','accuracy= '+str(total_accuracy)[0:6]+'%']\n",
    "    new_Df.loc['Total'][columns]=['' for i in range(len(columns))]\n",
    "    \n",
    "    return new_Df # return the adapted confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(classifier, sample_size, X_train, X_test, y_train,  y_test,typ): \n",
    "    \n",
    "    # inputs:\n",
    "    #   classifier: the learning algorithm to be trained and predicted on\n",
    "    #   sample_size: the size of samples (number) to be drawn from training set\n",
    "    #   X_train: features training set\n",
    "    #   y_train: Activity_number_ID training set\n",
    "    #   X_test: features testing set\n",
    "    #   y_test: Activity_number_ID testing set\n",
    "    \n",
    "    # Empty dictionary will include all dataframes and info related to training and testing.\n",
    "    results = {}\n",
    "    \n",
    "    # Fitting the classifier to the training data using slicing with 'sample_size'\n",
    "    start= timer() # Get start time\n",
    "    classifier = classifier.fit(X_train[0:sample_size,:],y_train[0:sample_size])# fiting the classfier\n",
    "    end = timer() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end-start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 3000 training samples(X_train) using .predict()\n",
    "    start = timer() # Get start time\n",
    "    predictions_test = classifier.predict(X_test) # predict\n",
    "    predictions_train =classifier.predict(X_train[:3000,:])\n",
    "    end = timer() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] =end-start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy(y_train[:3000],predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy(y_test,predictions_test)\n",
    "    \n",
    "    # Adapting the confusion matrix shape to the type of data used\n",
    "    if typ==1:\n",
    "        #confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6], sample_weight=None) # \n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6,7,8,9,10,11,12], sample_weight=None) # \n",
    "       # columns=['WK','WU','WD','SI','ST','LD']\n",
    "        # index=['WK','WU','WD','SI','ST','LD']\n",
    "        columns = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "        index = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "    if typ==2:\n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6,7,8,9,10,11,12], sample_weight=None)\n",
    "       # columns=['WK','WU','WD','SI','ST','LD','St-Si','Si-St','Si-Li','Li-Si','St-Li','Li-St']\n",
    "        # index=  ['WK','WU','WD','SI','ST','LD','St-Si','Si-St','Si-Li','Li-Si','St-Li','Li-St'] \n",
    "        columns = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "        index = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "    if typ==3:   \n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6,7], sample_weight=None)\n",
    "       # columns=['WK','WU','WD','SI','ST','LD','PT']\n",
    "      #  index=['WK','WU','WD','SI','ST','LD','PT']\n",
    "        columns = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "        index = ['HaS','HiA','ThS','HiF','LuR','LuF','Abd','Add','HoF','HoE','VeF','ShI']\n",
    "    \n",
    "    if sample_size==len(X_train):# if 100% of training is achieved\n",
    "        # apply the confusion matrix function to the last contingency table generated\n",
    "        confusion_matrix_df=(pd.DataFrame(data=confusion_matrix,columns=columns,index=index)).pipe(full_confusion_matrix)\n",
    "    else:# if not\n",
    "        # create a dataframe from the contingency table\n",
    "        confusion_matrix_df=pd.DataFrame(data=confusion_matrix,columns=columns,index=index)\n",
    "        \n",
    "    # Return the results\n",
    "    return (results,confusion_matrix_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_report(classifier,dataset_type):\n",
    "    # Inputs:\n",
    "    #  classifier: model will be trained tested and evaluated on all sample sizes\n",
    "    #  Dataset_type: \"All\"  or integers 1,2,3 \n",
    "    # if \"All\" the classifier will be trained, tested and evaluated on all datasets\n",
    "    # if integer 1, 2 or 3: the classifier the classifier will be trained, tested and evaluated on one dataset(I,II or III)\n",
    "    \n",
    "    if dataset_type!='All': # dataset type equal to 1 ,2 or 3\n",
    "        # extract train and test files related to dataset type\n",
    "        new_dic={dataset_type:train_test_files_dic[dataset_type]}\n",
    "    \n",
    "    else:# the model will be trained , tested and evaluted on all datasets\n",
    "        new_dic=train_test_files_dic # import all train and test files\n",
    "    \n",
    "    for key in sorted(new_dic.keys()):# iterating throw dataset types\n",
    "        clf=classifier # reintialize the classifier\n",
    "        # adapt the dataset name switch the case\n",
    "        if key==1:\n",
    "            Dataset_name='Dataset_Train'\n",
    "        if key==2:\n",
    "            Dataset_name='Dataset_Test'\n",
    "       \n",
    "        \n",
    "        files = new_dic[key] # copy train and test files related to the dataset type\n",
    "        # create a temporal dictionary where train, test and evaluation results will be stored\n",
    "        results = {}\n",
    "        print(\"_____________________\"+Dataset_name+\" Training and Testing______________________\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # copy train and test files\n",
    "        X_train, X_test, y_train, y_test,= files[0], files[1], files[2], files[3]\n",
    "        # extract the name of the classifier\n",
    "        clf_name = clf.__class__.__name__\n",
    "        \n",
    "        # training started\n",
    "        print(\"{} started training....\".format(clf_name) )   \n",
    "        \n",
    "        results[clf_name] = {}\n",
    "        # generate sample sizes\n",
    "        samples_10 = int(len(X_train)/10) # 10%\n",
    "        samples_50 = int(len(X_train)/2) # 50%\n",
    "        samples_100 = int(len(X_train)) # 100%\n",
    "        \n",
    "        \n",
    "        for i, samples in enumerate([samples_10, samples_50, samples_100]): # iterate throw each sample size\n",
    "            print(\"...\")\n",
    "            if samples==len(X_train):# when 100% of training will be achieved\n",
    "                # store results related to the classier and sample size in results dictionary\n",
    "                # store the full confusion matrix\n",
    "                results[clf_name][i],confusion_matrix = train_predict(clf, samples, X_train, X_test, y_train, y_test,key)\n",
    "            else:# if not\n",
    "                # store results related to the classier and sample size in results dictionary\n",
    "                results[clf_name][i]= train_predict(clf, samples, X_train,X_test, y_train,  y_test,key)[0]\n",
    "\n",
    "        print( \"Success: {} Finished Training and Testing.\".format(clf_name))\n",
    "        print(\"\")\n",
    "        print (\"________\"+clf_name+\" results:__________\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"Accuracy and duration per training size\")\n",
    "        # display train and test results\n",
    "        display(pd.DataFrame(results[clf_name]).rename(columns={0:'10% of train', 1:'50% of train', 2:'100% of train'}))\n",
    "        print(\"\")\n",
    "        print(\"Confusion Matrix Sensitivity and Recall when 100% of train is achieved\")\n",
    "        # display the full confusion matrix results\n",
    "        display(confusion_matrix)\n",
    "        print(\"____________________________________________________________________\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VII. Benchmark Model\n",
    "# training, testing and evaluating the benchmark model on all datasets\n",
    "train_test_report(Benchmark_model,'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIII. Elected Models\n",
    "# Decision Tree Classifier\n",
    "\n",
    "# training, testing and evaluating Decision tree classifier on all datasets\n",
    "train_test_report(Clf1,'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "# training, testing and evaluating Logistic Regression  classifier on all datasets\n",
    "train_test_report(Clf2,'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IX. Tunning Parameters\n",
    "from sklearn.model_selection import GridSearchCV # import grid search cv to tune parameters\n",
    "clf_chosen=LR(random_state=337) # intialize the LR model\n",
    "\n",
    "# scaled dataset type I activity weights\n",
    "weights_dic_1= {1:0.179248,2:0.15867,3:0.144265,4:0.161919,5:0.17849,6:0.177407}\n",
    "\n",
    "# scaled dataset type II activity weights\n",
    "weights_dic_2={1 : 0.164576, 2 : 0.150152, 3 : 0.142537, 4 : 0.145225,\n",
    "               5 : 0.156961, 6 : 0.155169, 7 : 0.012991, 8 : 0.009138,\n",
    "               9 : 0.015857, 10: 0.015320, 11: 0.018903,12 : 0.013170}\n",
    "# scaled dataset type III activity weights\n",
    "weights_dic_3={1:0.164576,2:0.150152,3:0.142537,4:0.145225,5:0.156961,6:0.155169,7:0.085379}\n",
    "\n",
    "# possible values for the parameter \"class_weight\" for each dataset\n",
    "\n",
    "class_weight_1=[None,weights_dic_1] # scaled dataset I\n",
    "class_weight_2=[None,weights_dic_2] # scaled dataset II\n",
    "class_weight_3=[None,weights_dic_3] # scaled dataset III\n",
    "\n",
    "# possible parameters dictionary for each dataset:\n",
    "\n",
    "# dataset type I\n",
    "params_1={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_1}\n",
    "params_2={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_1}\n",
    "params_3={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_1}\n",
    "\n",
    "# dataset type II\n",
    "params_4={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_2}\n",
    "params_5={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_2}\n",
    "params_6={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_2}\n",
    "\n",
    "# dataset type III\n",
    "params_7={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_3}\n",
    "params_8={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_3}\n",
    "params_9={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset type I:\n",
    "# insert parameters in the grid seach for each path \n",
    "# store each future results in a model\n",
    "tuned_model1 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_1)\n",
    "tuned_model2 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_2)\n",
    "tuned_model3 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_3)\n",
    "\n",
    "# train models\n",
    "tuned_model1.fit(X_1_train,y_1_train)\n",
    "tuned_model2.fit(X_1_train,y_1_train)\n",
    "tuned_model3.fit(X_1_train,y_1_train)\n",
    "\n",
    "# display best parameters of each model\n",
    "print(\"Tuned model 1 best params:\",tuned_model1.best_params_)\n",
    "print(\"Tuned model 2 best params:\",tuned_model2.best_params_)\n",
    "print(\"Tuned model 3 best params:\",tuned_model3.best_params_)\n",
    "\n",
    "# store predictions and generate accuracies for each model\n",
    "predictions1=tuned_model1.predict(X_1_test)\n",
    "print( \"tuned model 1 accuracy:\",accuracy(y_1_test,predictions1))\n",
    "\n",
    "predictions2=tuned_model2.predict(X_1_test)\n",
    "print( \"tuned model 2 accuracy:\",accuracy(y_1_test,predictions2))\n",
    "\n",
    "predictions3 = tuned_model3.predict(X_1_test)\n",
    "print( \"tuned model 3 accuracy:\",accuracy(y_1_test,predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset : same process will be applied for dataset \n",
    "tuned_model4 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_4)\n",
    "tuned_model5 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_5)\n",
    "tuned_model6 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_6)\n",
    "\n",
    "tuned_model4.fit(X_2_train,y_2_train)\n",
    "tuned_model5.fit(X_2_train,y_2_train)\n",
    "tuned_model6.fit(X_2_train,y_2_train)\n",
    "\n",
    "print(\"Tuned model 4 best params:\",tuned_model4.best_params_)\n",
    "print(\"Tuned model 5 best params:\",tuned_model5.best_params_)\n",
    "print(\"Tuned model 6 best params:\",tuned_model6.best_params_)\n",
    "\n",
    "predictions4=tuned_model4.predict(X_2_test)\n",
    "print( \"tuned model 4 accuracy:\",accuracy(y_2_test,predictions4))\n",
    "\n",
    "predictions5=tuned_model5.predict(X_2_test)\n",
    "print( \"tuned model 5 accuracy:\",accuracy(y_2_test,predictions5))\n",
    "\n",
    "predictions6=tuned_model6.predict(X_2_test)\n",
    "print( \"tuned model 6 accuracy:\",accuracy(y_2_test,predictions6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset : same process will be applied for dataset \n",
    "\n",
    "tuned_model7 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_7)\n",
    "tuned_model8 =GridSearchCV(estimator =clf_chosen,\n",
    "                       param_grid=params_8)\n",
    "tuned_model9 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_9)\n",
    "\n",
    "tuned_model7.fit(X_3_train,y_3_train)\n",
    "tuned_model8.fit(X_3_train,y_3_train)\n",
    "tuned_model9.fit(X_3_train,y_3_train)\n",
    "\n",
    "print(\"Tuned model 7 best params:\",tuned_model7.best_params_)\n",
    "print(\"Tuned model 8 best params:\",tuned_model8.best_params_)\n",
    "print(\"Tuned model 9 best params:\",tuned_model9.best_params_)\n",
    "\n",
    "predictions7=tuned_model7.predict(X_3_test)\n",
    "print( \"tuned model 7 accuracy:\",accuracy(y_3_test,predictions7))\n",
    "\n",
    "predictions8=tuned_model8.predict(X_3_test)\n",
    "print( \"tuned model 8 accuracy:\",accuracy(y_3_test,predictions8))\n",
    "\n",
    "predictions9=tuned_model9.predict(X_3_test)\n",
    "print( \"tuned model 9 accuracy:\",accuracy(y_3_test,predictions9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter C Search:\n",
    "# Warning: Running duration of this part is a least 5 hours\n",
    "\n",
    "# C values from 0.1 to 20 with a step of 0.1\n",
    "C_values=[(i+1)*0.1 for i in range(200)]       \n",
    "\n",
    "def max_c(results,typ):\n",
    "    # inputs:\n",
    "    #   results: dictionary={c_value: accuracy of the model}\n",
    "    #   typ: float possible values are: 1,2,3 and 3.5\n",
    "    \n",
    "    # extract C values\n",
    "    C_values=sorted(results.keys())\n",
    "    # extract related accuracies \n",
    "    accuracy_values=[results[key] for key in C_values]\n",
    "    \n",
    "    # extract c value having the maximum accuracy\n",
    "    max_c=C_values[np.array(accuracy_values).argmax()]\n",
    "    \n",
    "    # display results\n",
    "    print(\"max accuracy :\",max(accuracy_values))\n",
    "    print(\"C value:\",max_c)\n",
    "    \n",
    "    plt.plot(C_values,accuracy_values)# plot the curve\n",
    "    plt.xlabel(\"C values\")  # set X axis info\n",
    "    plt.ylabel(\"accuracy\") # set Y axis info\n",
    "    \n",
    "    # Set the right title switch the case\n",
    "    if typ==1:# if dataset type I\n",
    "        plt.title(\"model 1 accuracy variation on dataset_Train\")\n",
    "    if typ==2:# if dataset type II\n",
    "        plt.title(\"model 5 accuracy variation on dataset_Test\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the search function below for dataset type 1 decomment the last line\n",
    "\n",
    "# Dataset type I\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    accuracy_results={} # empty dictionary will contain c values and accuracies related\n",
    "    \n",
    "    for value in C_values:# iterate throw each C value\n",
    "        #tuned model 1 best parameters + C variable\n",
    "        tmp_model=LR(solver='lbfgs',class_weight= None,multi_class= 'ovr', \n",
    "                  dual=False, penalty= 'l2',random_state=337,C=value)\n",
    "        # train the model\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        \n",
    "        # predicting activity labels\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        # accuracy score\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        # store the tuple c_value and accuracy value in the dictionary\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    \n",
    "    # after iterating throw all c values\n",
    "    return accuracy_results # return results\n",
    "\n",
    "# apply lookup_best_c to train and test files type I\n",
    "#results_I = lookup_best_c(X_1_train,y_1_train,X_1_test,y_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_I,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the search function below for dataset type 2 models decomment the last line\n",
    "# same process will be applied for dataset type II model\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    i=0\n",
    "    accuracy_results={}\n",
    "    for value in C_values:\n",
    "        \n",
    "        #tuned model 5 best parameters + C variable\n",
    "        tmp_model=LR(solver='liblinear', class_weight= None, multi_class= 'ovr',\n",
    "                  dual= True, penalty= 'l2',random_state=337,C=value)\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    return accuracy_results\n",
    "\n",
    "# apply lookup_best_c to train and test files type II\n",
    "#results_II =lookup_best_c(X_2_train,y_2_train,X_2_test,y_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize results_II, Decomment the last line of the cell below\n",
    "# visualizing results\n",
    "#max_c(results_II,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "final_model_I=LR(solver='lbfgs',class_weight= None,multi_class= 'ovr', \n",
    "                  dual=False, penalty= 'l2',random_state=337,C=4.7)\n",
    "final_model_II=LR(solver='liblinear', class_weight= None, multi_class= 'ovr',\n",
    "                  dual= True, penalty= 'l2',random_state=337,C=0.8)\n",
    "\n",
    "# for dataset type III model 7 best parameters + best C value have the highest accuracy compared to model 8 best C value \n",
    "final_model_III=LR(solver= 'newton-cg', class_weight= None, multi_class= 'ovr', \n",
    "                  dual= False, penalty= 'l2',random_state=337,C=8.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train, test and evaluate final model I on dataset type I\n",
    "train_test_report(final_model_I,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Some Samples\n",
    "# test samples indexes for each dataset\n",
    "indexes_I=[0,500,300,800,900,1000]\n",
    "indexes_II=[91,134,124,14,0,46,189,27,72,56,40,89]\n",
    "\n",
    "# activity labels for dataset \n",
    "AL={\n",
    "1:'Hip-adducator-stretch', 2: 'Hip-Abduction', 3: 'Towel-hamstring-stretch', 3 dynamic activities\n",
    "4: 'Hip-Fracture', 5: 'Lumbar-Rotation', 6: 'Lumbar-Flexsion', 7: 'Abduction', # static activities\n",
    "# activity labels for dataset \n",
    "AL3={8: 'Adduction', 9: 'Horizontal-Flexion', 10: 'Horizontal-extension', # 3 static activities\n",
    "11: 'Vertical-Flexion', 12:'Shoulder-Impingement',}\n",
    "\n",
    "\n",
    "def Samples_Results(x_test,y_test,model,samples_index,dataset_type):\n",
    "    # Inputs:\n",
    "    #  X_test: 2D numpy array (test features)\n",
    "    #  y_test: 1D numpy array (test labels)\n",
    "    #  sample index: integer from 0 to lenght of X_test-1    \n",
    "    # Dataset type: integer possible values are 1,2 or 3\n",
    "    \n",
    "    # Intialize a pandas dataframe will contain predictions' results\n",
    "    Df=pd.DataFrame(data=[],columns=['Row index','real identifier','predicted identifier'])\n",
    "    \n",
    "    for indice in samples_index:# iterate throw indicies\n",
    "        \n",
    "        real_value=int(y_test[indice]) # activity label of the sample\n",
    "        features_row=x_test[indice,:] # features vector of the sample\n",
    "        \n",
    "        prediction=int(model.predict(features_row)) # predicted activity label\n",
    "        # Adapting the activity name switch the dataset type\n",
    "        if dataset_type==1:\n",
    "            activity_name=AL[real_value]\n",
    "        if dataset_type==2:\n",
    "            activity_name=AL[real_value]\n",
    "        if dataset_type==3:\n",
    "            activity_name=AL3[real_value]\n",
    "        \n",
    "        # append the row index the activity id and the predicted activity id\n",
    "        Df.loc[activity_name]=[indice,real_value,prediction]\n",
    "    return Df # return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the final model I on dataset \n",
    "final_model_I.fit(X_1_train,y_1_train)\n",
    "# display results\n",
    "Samples_Results(X_1_test,y_1_test,final_model_I,indexes_I,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 5 load Data\n",
    "#data1 = pd.read_csv(\"E:\\Google Colab\\SAR_v2.3\\SAR_v2.3_raw_test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 = pd.read_csv(SAR_v2.3_raw_all_xy.txt\")\n",
    "#data2 = pd.read_csv(\"E:\\Google Colab\\SAR_v2.3\\SAR_v2.3_raw_all_xy.txt\")              \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = pd.read_csv(r\"E:\\Google Colab\\SAR_v2.3\\SAR_v2.3_raw_test1.csv\")\n",
    "#data2 = pd.read_csv(SAR_v2.3_raw_all_xy_csv.csv\")\n",
    "#data1 = pd.read_csv(SAR_v2.3_raw_all_xy.txt\")\n",
    "data2 = pd.read_csv(\"E:\\Google Colab/SAR_v2.3/SAR_v2.3_raw_test1.txt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara 6 load Data\n",
    "df = pd.read_csv(\"E:\\Google Colab\\\\SAR_v2.3\\SAR_v2.3_raw_all_xy_csv.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DQfJm0tMrR-"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_data(data_path, split = \"train\"):\n",
    "\t\"\"\" Read data \"\"\"\n",
    "\n",
    "\t# Fixed params\n",
    "\tn_class = 6\n",
    "\tn_steps = 128\n",
    "\n",
    "\t# Paths\n",
    "\tpath_ = os.path.join(data_path, split)\n",
    "\tpath_signals = os.path.join(path_, \"Inertial_Signals\")\n",
    "\n",
    "\t# Read labels and one-hot encode\n",
    "\tlabel_path = os.path.join(path_, \"x_\" + split + \".csv\")\n",
    "\tlabels = pd.read_csv(label_path, header = None)\n",
    "\n",
    "\t# Read time-series data\n",
    "\tchannel_files = os.listdir(path_signals)\n",
    "\tchannel_files.sort()\n",
    "\tn_channels = len(channel_files)\n",
    "\tposix = len(split) + 5\n",
    "\n",
    "\t# Initiate array\n",
    "\tlist_of_channels = []\n",
    "\tX = np.zeros((len(labels), n_steps, n_channels))\n",
    "\ti_ch = 0\n",
    "\tfor fil_ch in channel_files:\n",
    "\t\tchannel_name = fil_ch[:-posix]\n",
    "\t\tdat_ = pd.read_csv(os.path.join(path_signals,fil_ch), delim_whitespace = True, header = None)\n",
    "\t\tX[:,:,i_ch] = dat_.as_matrix()\n",
    "\n",
    "\t\t# Record names\n",
    "\t\tlist_of_channels.append(channel_name)\n",
    "\n",
    "\t\t# iterate\n",
    "\t\ti_ch += 1\n",
    "\n",
    "\t# Return \n",
    "\treturn X, labels[0].values, list_of_channels\n",
    "\n",
    "def standardize(train, test):\n",
    "\t\"\"\" Standardize data \"\"\"\n",
    "\n",
    "\t# Standardize train and test\n",
    "\tX_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "\tX_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "\n",
    "\treturn X_train, X_test\n",
    "\n",
    "def one_hot(labels, n_class = 6):\n",
    "\t\"\"\" One-hot encoding \"\"\"\n",
    "\texpansion = np.eye(n_class)\n",
    "\ty = expansion[:, labels-1].T\n",
    "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "\treturn y\n",
    "\n",
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Return a generator for batches \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZeUUBeuMzUd"
   },
   "source": [
    "explore_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSdLL9nOOSQ9"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2wMX_inOMlN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0vM5ue2OcuF"
   },
   "outputs": [],
   "source": [
    "#X_train, labels_train, list_ch_train = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_all_xy_csv.csv\", split=\"train\") # train\n",
    "#X_test, labels_test, list_ch_test = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv\", split=\"test\") # test\n",
    "X_train, labels_train, list_ch_train = read_data(data_path=(\"E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=(\"E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv\", split=\"test\") # test                           \n",
    "                                              \n",
    "                                              \n",
    "                                              \n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2vLTmFJO0K0"
   },
   "outputs": [],
   "source": [
    "print (\"Training data shape: N = {:d}, steps = {:d}, channels = {:d}\".format(X_train.shape[0],\n",
    "                                                                             X_train.shape[1],\n",
    "                                                                             X_train.shape[2]))\n",
    "print (\"Test data shape: N = {:d}, steps = {:d}, channels = {:d}\".format(X_test.shape[0],\n",
    "                                                                         X_test.shape[1],\n",
    "                                                                         X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-jRSgtNPOM0"
   },
   "source": [
    "Training data shape: N = 7352, steps = 128, channels = 9\n",
    "Test data shape: N = 2947, steps = 128, channels = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Txzoct_PkI2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mean value for each channel at each step\n",
    "all_data = np.concatenate((X_train,X_test), axis = 0)\n",
    "means_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "stds_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "\n",
    "for ch in range(X_train.shape[2]):\n",
    "    means_[:,ch] = np.mean(all_data[:,:,ch], axis=0)\n",
    "    stds_[:,ch] = np.std(all_data[:,:,ch], axis=0)\n",
    "    \n",
    "df_mean = pd.DataFrame(data = means_)\n",
    "df_std = pd.DataFrame(data = stds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jy7uJc12TrDq"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_std.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcH3ZscGYqLQ"
   },
   "outputs": [],
   "source": [
    "df_std.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wyr8zQKdYtfr"
   },
   "source": [
    "Some channels have mean values near 1, most close to 0. Let's standardize them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVlDaSUEYvK3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI9jAAJuYxsn"
   },
   "outputs": [],
   "source": [
    "# Check Mean value for each channel at each step\n",
    "all_data = np.concatenate((X_train,X_test), axis = 0)\n",
    "means_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "stds_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "\n",
    "for ch in range(X_train.shape[2]):\n",
    "    means_[:,ch] = np.mean(all_data[:,:,ch], axis=0)\n",
    "    stds_[:,ch] = np.std(all_data[:,:,ch], axis=0)\n",
    "    \n",
    "df_mean = pd.DataFrame(data = means_)\n",
    "df_std = pd.DataFrame(data = stds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJJDLcVdYztf"
   },
   "outputs": [],
   "source": [
    "df_mean.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "914n4p8vdLP9"
   },
   "source": [
    "# 0 HAR-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPQ70HbMdROu"
   },
   "source": [
    "https://github.com/hardik04021996/Human-Activity-Recognition-using-machine-learning/blob/master/SVM%2Bfor%2BHuman%2BActivity%2BRecognition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpuIpFo0dYYA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5YUzWfvfjul"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = pd.concat([xtrain, xtest], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXW7nCr4f1FN"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soVn69Srf8Rm"
   },
   "outputs": [],
   "source": [
    "x2 = x\n",
    "x2 = np.asarray(x2)\n",
    "x2 = pd.DataFrame(x2)\n",
    "x2[0][367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucCsLXE5huqK"
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(x2)):\n",
    "    if(y2[0][i] == 1):\n",
    "x2[0][i] = 'Hip-adducator-stretch'\n",
    "    elif(x2[0][i] == 2):\n",
    "x2[0][i] = 'Hip-Abduction'\n",
    "    elif(x2[0][i] == 3):\n",
    "x2[0][i] = 'Towel-hamstring-stretch'\n",
    "    elif(x2[0][i] == 4):\n",
    " x2[0][i] = 'Hip-Fracture'\n",
    "    elif(x2[0][i] == 5):\n",
    "x2[0][i] = 'Lumbar-Rotation'\n",
    "    elif(x2[0][i] == 6):\n",
    "x2[0][i] = 'Lumbar-Flexsion'\n",
    "    elif(x2[0][i] == 7):\n",
    " x2[0][i] = 'Abduction'\n",
    "    elif(x2[0][i] == 8):\n",
    "x2[0][i] = 'Adduction'\n",
    "    elif(x2[0][i] == 9):\n",
    "x2[0][i] = 'Horizontal-Flexion'\n",
    "    elif(x2[0][i] == 10):\n",
    " x2[0][i] = 'Horizontal-extension'\n",
    "    elif(x2[0][i] == 11):\n",
    " x2[0][i] = 'Vertical-Flexion'\n",
    "    elif(x2[0][i] == 12):\n",
    "x2[0][i] = 'Shoulder-Impingement’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf8GNpNlh5MW"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXmuS40rh8Va"
   },
   "outputs": [],
   "source": [
    "#PCA algorithm being used for the dimensionality reduction process\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYSEemakh93T"
   },
   "outputs": [],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQw-wyY5h_86"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_trans = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgdWzufPiBcy"
   },
   "outputs": [],
   "source": [
    "X_trans = pd.DataFrame(X_trans, columns = ['F1', 'F2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRv_25BniCsC"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxcIWgvCiFDi"
   },
   "outputs": [],
   "source": [
    "X_trans['label'] = x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwh1o2WciIwC"
   },
   "outputs": [],
   "source": [
    "X_trans.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLUE0Y-miKyK"
   },
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzfaM1WDiMlC"
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'F1', y = 'F2', data = X_trans, hue = 'label',  fit_reg = False, x_jitter = 4.25, y_jitter = 2.4, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3jAgM4HiU4r"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel('Train')\n",
    "\n",
    "plt.ylabel('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OXNLUhcid1U"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jIPhnNnif6y"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUDBYpCFiiPq"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (18, 10))\n",
    "sns.countplot(x = 'label', data = X_train)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1KGcwa7inqz"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHdWrZDVir1K"
   },
   "outputs": [],
   "source": [
    "\n",
    "#hexagonal joint mapping plot for the data\n",
    "plt.figure(figsize = (15, 10))\n",
    "sns.jointplot(x= 'F1', y = 'F2', data = X_trans, kind = 'hex', color = 'red', size = 15 )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tv1xKcakitDQ"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2ise3uUive9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sns.pairplot(X_train, hue = 'label', size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeJaWZG2iywK"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMLaPSqedhK8"
   },
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dF-OcI4tds1E"
   },
   "outputs": [],
   "source": [
    "#X_train, labels_train, list_ch_train = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_all_xy_csv.csv\", split=\"train\") # train\n",
    "#X_test, labels_test, list_ch_test = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv\", split=\"test\") # test\n",
    "\n",
    "                                              \n",
    "X_train, labels_train, list_ch_train = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv', split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv', split=\"test\") # test\n",
    "     \n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaYQKK13d1cl"
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "# Normalize\n",
    "#X_train = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw__all_xy_csv.csv;\n",
    "#X_test = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv;\n",
    "X_train = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv')\n",
    "X_test = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95gTfUj6eFKz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCaRdq6XeFYw"
   },
   "outputs": [],
   "source": [
    "classifier=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDbItzEDeFkV"
   },
   "outputs": [],
   "source": [
    "parameters=[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70frpcsJeFrJ"
   },
   "outputs": [],
   "source": [
    "model=GridSearchCV(classifier,parameters,n_jobs=-1,cv=4,verbose=4)\n",
    "model.fit(xtrain.as_matrix(),ytrain.as_matrix().ravel().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k1tlbvJeZ7X"
   },
   "source": [
    "GridSearchCV(cv=4, error_score='raise',\n",
    "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid=[{'kernel': ['rbf'], 'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}],\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuoUPNhoeFxz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ypred=model.predict(Xtest)\n",
    "accuracy=accuracy_score(Xtrain, Xpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxVZhErReF_r"
   },
   "outputs": [],
   "source": [
    "print 'Best Parameters: '+ str(model.best_params_)\n",
    "print 'Accuracy Score: '+ str(accuracy*100) + ' %'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdGoGtEZW7IQ"
   },
   "source": [
    "Kernel SVM with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPBhF7IGW5Zj"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[2,8,16],\\\n",
    "              'gamma': [ 0.0078125, 0.125, 2]}\n",
    "rbf_svm = SVC(kernel='rbf')\n",
    "rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters,n_jobs=8)\n",
    "rbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_5eMFWke_Lo"
   },
   "source": [
    "# 0 HAR-RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NX0sgZ1seFu0"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIohodHeFn7"
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mZWmVnweFc8"
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [10, 100, 1000], 'max_depth': [3, 6, 9], 'max_features' : ['auto', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0v8_5cSveFSB"
   },
   "outputs": [],
   "source": [
    "model=GridSearchCV(classifier,parameters,n_jobs=-1,cv=4,scoring='accuracy',verbose=4)\n",
    "model.fit(X_train.as_matrix(),ytrain.as_matrix().ravel().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqJk_5kTfTGT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ypred=model.predict(xtest)\n",
    "accuracy=accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT_E9dVnfTVk"
   },
   "outputs": [],
   "source": [
    "\n",
    "print 'Best Parameters: '+ str(model.best_params_)\n",
    "print 'Accuracy Score: '+ str(accuracy*100) + ' %'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr9e71XGXD-G"
   },
   "source": [
    "Decision Trees with GridSearchCV\n",
    "https://github.com/UdiBhaskar/Human-Activity-Recognition--Using-Deep-NN/blob/master/Human%20Activity%20Detection-Without%20Verbose%20.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dH3Zcmi4fSRI"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth':np.arange(3,10,2)}\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=8)\n",
    "dt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
    "print_grid_search_attributes(dt_grid_results['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXsuzqjOeFB4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSTr_hb1Y2CA"
   },
   "source": [
    "https://github.com/bhimmetoglu/time-series-medicine/blob/master/HAR/explore_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K19OqrjUBsAM"
   },
   "source": [
    "# HAR-CNN;LSTM,CNN-LSTM; CNN Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDy2wWB4BwG0"
   },
   "source": [
    "# 1 HAR-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgirshGGEXCw"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrngAhGSCBcj"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwlBFPJGnRom"
   },
   "outputs": [],
   "source": [
    "#X_train, labels_train, list_ch_train = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_all_xy_csv.csv\", split=\"train\") # train\n",
    "#X_test, labels_test, list_ch_test = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv\", split=\"test\") # test\n",
    "\n",
    "X_train, labels_train, list_ch_train = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv', split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv', split=\"test\") # test\n",
    "  \n",
    "                                              \n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzewVfSFicRA"
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "# Normalize\n",
    "#X_train = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw__all_xy_csv.csv;\n",
    "#X_test = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv;\n",
    "\n",
    "X_train = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv')\n",
    "X_test = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDk_qWUqEDHb"
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NW6e-ZcYicjp"
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv5kD9lLEQdh"
   },
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FahtzTfTicqh"
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7H0QsEOicnJ"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Foc1rQaUEgyZ"
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsL207xkicfk"
   },
   "outputs": [],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs =1000\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4_BhM8jEmex"
   },
   "source": [
    "Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwoEIMPPicFE"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AHRvGuAEsNh"
   },
   "source": [
    "Build Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IueyUabDib5m"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 18)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 18) --> (batch, 16, 36)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 36) --> (batch, 8, 36)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDfHPLXdEyl5"
   },
   "source": [
    "Build the inception layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50VmKmQsE2Gw"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koIF8WSoibnl"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    \n",
    "    # convolution: input to output of inception (size=1)\n",
    "    # (batch, 8, 36) --> (batch, 8, 36)\n",
    "    conv1_11 = tf.layers.conv1d(inputs=max_pool_4, filters=36, kernel_size=1, strides=1,\n",
    "                               padding='same', activation = tf.nn.relu)\n",
    "    \n",
    "    # convolution: input to middle layer of inception (size=1)\n",
    "    # (batch, 8, 36) --> (batch, 8, 18)\n",
    "    conv1_21 = tf.layers.conv1d(inputs=max_pool_4, filters=18, kernel_size=1, strides=1,\n",
    "                               padding='same', activation = tf.nn.relu)\n",
    "    \n",
    "    # convolution: input to middle layer of inception (size=1)\n",
    "    # (batch, 8, 36) --> (batch, 8, 18)\n",
    "    conv1_31 = tf.layers.conv1d(inputs=max_pool_4, filters=18, kernel_size=1, strides=1,\n",
    "                               padding='same', activation = tf.nn.relu)\n",
    "    \n",
    "    # average pool: input to middle layer of inception\n",
    "    # (batch, 8, 36) --> (batch, 8, 36)\n",
    "    avg_pool_41 = tf.layers.average_pooling1d(inputs=max_pool_4, pool_size=2, strides=1, padding='same')\n",
    "    \n",
    "    ## Middle layer of inception\n",
    "    \n",
    "    # convolution: middle to out layer of inception (size=2)\n",
    "    # (batch, 8, 18) --> (batch, 8, 36)\n",
    "    conv2_22 = tf.layers.conv1d(inputs=conv1_21, filters=36, kernel_size=2, strides=1,\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    # convolution: middle to out layer of inception (size=4)\n",
    "    # (batch, 8, 18) --> (batch, 8, 36)\n",
    "    conv4_32 = tf.layers.conv1d(inputs=conv1_31, filters=36, kernel_size=4, strides=1,\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    # convolution: middle to out layer of inception (size=1)\n",
    "    # (batch, 8, 36) --> (batch, 8, 36)\n",
    "    conv1_42 = tf.layers.conv1d(inputs=avg_pool_41, filters=36, kernel_size=1, strides=1,\n",
    "                               padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    ## Out layer: Concatenate filters\n",
    "    # (batch, 8, 4*36)\n",
    "    inception_out = tf.concat([conv1_11, conv2_22, conv4_32, conv1_42], axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOMpEPV8FJCx"
   },
   "source": [
    "Flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BL3ibaRf2AXY"
   },
   "outputs": [],
   "source": [
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(inception_out, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMPiCEwdFPXx"
   },
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW_CuO7S6lXP"
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVbl729q19Ay"
   },
   "outputs": [],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1XTo7rjrzp3"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMLXsmB41CpC"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AqKVJ-bFmoJ"
   },
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Plw0T3481C10"
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcyQBBufVyd5"
   },
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'SAR',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "plt.plot(indep_test_axis, np.array(test_losses),     \"b-\", label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSBPtESeT2DN"
   },
   "source": [
    "The multi-class confusion matrix and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bjp3XSSlWAgC"
   },
   "source": [
    "https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G648XMjmVpG1"
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results:\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix,\n",
    "    interpolation='nearest',\n",
    "    cmap=plt.cm.rainbow )\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkyJdMFtX_RQ"
   },
   "source": [
    "https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tH6ARVoe1CdW"
   },
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "#plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "#plt.plot(indep_test_axis, np.array(test_losses), \"b-\", linewidth=2.0, label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"b-\", linewidth=2.0, label=\"Test accuracies\")\n",
    "print len(test_accuracies)\n",
    "print len(train_accuracies)\n",
    "\n",
    "plt.title(\"Training session's Accuracy over Iterations\")\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Training Iteration')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"Created using test set of {} datapoints, normalised to % of each class in the test dataset\".format(len(y_test)))\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "\n",
    "\n",
    "#print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.Blues\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ig20QkMaG0QL"
   },
   "source": [
    "# 2 HAR LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rk2RS08zYlcB"
   },
   "source": [
    "# LSTM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DROs0RILOBbg"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uQxNBA4HGAw"
   },
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "FrcvGd4zuALt",
    "outputId": "3348a5a2-b702-4f45-99e3-80cd60dad5c0"
   },
   "outputs": [],
   "source": [
    "#X_train, labels_train, list_ch_train = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_all_xy_csv.csv\", split=\"train\") # train\n",
    "#X_test, labels_test, list_ch_test = read_data(data_path=(\"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv\", split=\"test\") # test\n",
    "\n",
    "X_train, labels_train, list_ch_train = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv', split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv', split=\"test\") # test\n",
    "  \n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSiq1eFGuA0P"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "# Data\n",
    "#X_train = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw__all_xy_csv.csv;\n",
    "#X_test = \"/content/drive/My Drive/SAR23/SAR_v2.3/SAR_v2.3_raw_test1.csv;\n",
    "\n",
    "Dataset_Train = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_all_xy_csv.csv')\n",
    "Dataset_Test = pd.read_csv('E:\\\\Google Colab/SAR_v2.3\\\\SAR_v2.3_raw_test1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwpQvKgCHXcg"
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXqw7a5fuBR2"
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPgzr2dLHqrv"
   },
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujc2qxJgy7Vz"
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8T87tIbHufo"
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgXppALyy7Ji"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufYtJZynH0Dg"
   },
   "source": [
    "Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6UKvIn4wmdn"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjo7XmZhH5hg"
   },
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeGiBQ5s7CFx"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K406AWhYH_OI"
   },
   "source": [
    "Define forward pass, cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28T08Zol5OL-"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSCIY7TtIF0P"
   },
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jf2lruJj3xcT"
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ffKB8mn3xyR"
   },
   "outputs": [],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdfUpIN73x8q"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3S7ag-03xp4"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddj1aAa8Idpv"
   },
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYjmjAY9IhxO"
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKDHziCFYxn5"
   },
   "source": [
    "LSTM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6jlj-5JY34j"
   },
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jx9xyKpZM4x"
   },
   "source": [
    "https://github.com/srvds/Human-Activity-Recognition/blob/master/HAR_LSTM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or-1vCoPZLHo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSrKSLS1ZQzX"
   },
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJRx6YOcZTyd"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrxwl0O6ZVu5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K8CWVyFZXmK"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvZct1HCZaDv"
   },
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqfgzlCSZnGH"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "#epochs = 30\n",
    "#batch_size = 16\n",
    "#n_hidden = 32\n",
    "#pv = 0.5\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden = 128\n",
    "pv = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCQgYVBrZp8Q"
   },
   "source": [
    "Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ps2bAMcZsBa"
   },
   "outputs": [],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "model.add(BatchNormalization())\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(pv))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MtkaxfUZvfX"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8iwRYJ9ZyDn"
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80rrJp3iZ0rj"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW7UczPuZ3Ec"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0JZHALDZbQB"
   },
   "source": [
    "LSTM Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJXtHWeFaAAH"
   },
   "source": [
    "stacking 2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCv4PNWjZ9g_"
   },
   "outputs": [],
   "source": [
    "epochs1 = 30\n",
    "batch_size1= 32\n",
    "n_hidden1 = 128\n",
    "n_hidden2 =64\n",
    "pv1 = 0.2\n",
    "pv2 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3tSvIp9aD6Q"
   },
   "source": [
    "Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5wFPZydaGSQ"
   },
   "outputs": [],
   "source": [
    "# Initiliazing the sequential model\n",
    "model1 = Sequential()\n",
    "# Configuring the parameters\n",
    "model1.add(LSTM(n_hidden1, return_sequences=True, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(pv1))\n",
    "\n",
    "model1.add(LSTM(n_hidden2))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(pv2))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model1.add(Dense(n_classes, activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9w8I6ig4aJdQ"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0041JUcdaLc2"
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model1.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2ybwfdKaN_i"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHI6xY2NaQ8F"
   },
   "outputs": [],
   "source": [
    "score1 = model1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjscxOKdaTcn"
   },
   "outputs": [],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4_vqjd2Ixcv"
   },
   "source": [
    "# 3 HAR CNN + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gligIXVI69Y"
   },
   "source": [
    "# (Code for Prepare data, Train/Validation Split, One-hot encoding are same as above) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Q63Te0Jjzo"
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR84XQo6Jhtd"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laKxYkqRJsFP"
   },
   "source": [
    "Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPkjwx-rJwI3"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ruWjzUbJyxO"
   },
   "source": [
    "Build Convolutional Layer(s)\n",
    "\n",
    "Questions:\n",
    "\n",
    "Should we use a different activation? Like tf.nn.tanh?\n",
    "Should we use pooling? average or max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2TJpjTxJ1xf"
   },
   "outputs": [],
   "source": [
    "# Convolutional layers\n",
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 128, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    n_ch = n_channels *2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umtRSQXgJ3zR"
   },
   "source": [
    "Pass to LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIApbHlJ72n"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(conv1, [1,0,2]) # reshape into (seq_len, batch, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_ch]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd3Ry01LJ-r4"
   },
   "source": [
    "Define forward pass and cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDw0_Hy0KBjm"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy59wA6bKEDH"
   },
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lh5LPU1tKF82"
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-crnn') == False):\n",
    "    !mkdir checkpoints-crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGOigJVFKK3u"
   },
   "outputs": [],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-crnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4K5hrwTKRqm"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsNuKYVeKWMH"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th-DOmQkKYfu"
   },
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7ldidLQKdBw"
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-crnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdHkcNqJevpn"
   },
   "source": [
    "let's plot this simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7TPPXsEevZ_"
   },
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'SAR',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "plt.plot(indep_test_axis, np.array(test_losses),     \"b-\", label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKPczqB2e3QX"
   },
   "source": [
    "The multi-class confusion matrix and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PrAlsjZe54U"
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results:\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix,\n",
    "    interpolation='nearest',\n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s9pb9sofaa0"
   },
   "source": [
    "Confusion matrix and metrics Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i7c1JDNfgfi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Draw the Confusion matrix\n",
    "def plot_Confusion_matrix(cm,title='Confusion matrix', cmap=plt.cm.Blues, labels=None):\n",
    "  # Show the confusion_matrix as an image\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  #plt.title(title)\n",
    "  plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "  plt.colorbar()\n",
    "  #Put labels on axis\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, LABELS, rotation=45) #rotation=90\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "#Pack it together\n",
    "plt.tight_layout()\n",
    "# Render the DataFrame as a table for easy view\n",
    "cmpd = pd.DataFrame(cm, columns=labels)\n",
    "cmpd.index = LABELS\n",
    "display(HTML('<b>Confusion matrix</b>'))\n",
    "display(cmpd)\n",
    "plt.ylabel('Real Activity')\n",
    "plt.xlabel('Predicted Activity')\n",
    "\n",
    "# Labels\n",
    "labels = map(lambda x: x[1], activity_map)\n",
    "#Compute Confusion matrix\n",
    "cm = confusion_matrix(y_real, y_pred, labels=labels)\n",
    "# Show the Confusion matrix\n",
    "plt.figure()\n",
    "plot_Confusion_matrix(cm, labels=labels)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GJUBGVnkp92"
   },
   "source": [
    "http://data-bloom.com/notebooks/Human%20Activity%20Recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eob0pfpekVt6"
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels = map(lambda x: x[1], activity_map)\n",
    "\n",
    "#Compute Confusion matrix\n",
    "cm = confusion_matrix(y_real, y_pred, labels=labels)\n",
    "\n",
    "# Show the Confusion matrix\n",
    "plt.figure()\n",
    "plot_Confusion_matrix(cm, labels=labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8fOJw2vWLFw"
   },
   "source": [
    "# 5 Tree Booster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I69zPVTVWcNg"
   },
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3T2KSSAWeVf"
   },
   "outputs": [],
   "source": [
    "library(plyr)\n",
    "library(dplyr)\n",
    "library(xgboost)\n",
    "library(MLmetrics)\n",
    "library(ggplot2)\n",
    "library(grid)\n",
    "library(gridExtra)\n",
    "\n",
    "source('prepare_data.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JYSpusSWg3T"
   },
   "source": [
    "Data cleaning and preparation is performed using prepare_data.py. Let’s first visualize the data using the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a167LpZyWpyQ"
   },
   "outputs": [],
   "source": [
    "X_tr <- X_full %>% filter(is.train == 1) %>% dplyr::select(-is.train) # Select training data\n",
    "pca_tr <- prcomp(X_tr) # Get principal components\n",
    "# Plot  \n",
    "dat_pca <- data.frame(pc1 = pca_tr$x[,1], pc2 = pca_tr$x[,2], pc3 = pca_tr$x[,3], \n",
    "                      label = as.factor(y_train$label))\n",
    "\n",
    "\n",
    "\n",
    "levels(dat_pca$label) <- c('Hip-adducator-stretch','Hip-Abduction','Towel-hamstring-stretch','Hip-Fracture',\n",
    "'Lumbar-Rotation','Lumbar-Flexsion','Abduction','Adduction','Horizontal-Flexion','Horizontal-extension','Vertical-Flexion','Shoulder-Impingement')\n",
    "\n",
    "\n",
    "\n",
    "g0 <- ggplot(data = dat_pca, aes(pc1, pc2)) + geom_point(aes(color = label))\n",
    "g0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TJHwuuxXBWf"
   },
   "source": [
    "If we were to look at principal components with lower variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ih3GzUWxXG7P"
   },
   "outputs": [],
   "source": [
    "# Plot  \n",
    "dat_pca <- data.frame(pc3 = pca_tr$x[,3], pc4 = pca_tr$x[,4], pc5 = pca_tr$x[,5], \n",
    "                      label = as.factor(y_train$label))\n",
    "levels(dat_pca$label) <- c('Hip-adducator-stretch','Hip-Abduction','Towel-hamstring-stretch','Hip-Fracture',\n",
    "'Lumbar-Rotation','Lumbar-Flexsion','Abduction','Adduction','Horizontal-Flexion','Horizontal-extension','Vertical-Flexion','Shoulder-Impingement')\n",
    "g1 <- ggplot(data = dat_pca, aes(pc4, pc5)) + geom_point(aes(color = label))\n",
    "g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq55-9ceXQWH"
   },
   "source": [
    "Gradient Boosting: Tree Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rvkbb3AXS1n"
   },
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "# Split back into train/test\n",
    "X_tr <- X_full %>% filter(is.train == 1) %>% dplyr::select(-is.train)\n",
    "X_tst <- X_full %>% filter(is.train == 0) %>% dplyr::select(-is.train)\n",
    "# XGboost wants levels to start with 0\n",
    "y_tr <- as.factor(y_train$label)\n",
    "y_tr <- revalue(y_tr, c('6'='5', '5'='4', '4'='3', '3'='2', '2'='1', '1'='0'))\n",
    "y_tr <- as.numeric(levels(y_tr))[y_tr]\n",
    "y_tst <- as.factor(y_test$label)\n",
    "y_tst <- revalue(y_tst, c('6'='5', '5'='4', '4'='3', '3'='2', '2'='1', '1'='0'))\n",
    "y_tst <- as.numeric(levels(y_tst))[y_tst]\n",
    "# XGB style matrices\n",
    "dtrain <- xgb.DMatrix(as.matrix(X_tr), label = y_tr)\n",
    "dtest <- xgb.DMatrix(as.matrix(X_tst), label = y_tst)\n",
    "watchlist <- list(train=dtrain, test=dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjsS5D4LXVYv"
   },
   "source": [
    "fit the tree booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caIC3RpZXX0H"
   },
   "outputs": [],
   "source": [
    "# Use best model params\n",
    "params <- list(booster = \"gbtree\",\n",
    "               eval_metric = \"mlogloss\",\n",
    "               objective = \"multi:softprob\",\n",
    "               eta = 0.50,     \n",
    "               max_depth = 2, \n",
    "               gamma = 0.0,    \n",
    "               min_child_weight = 0, \n",
    "               colsample_bytree = 0.2,\n",
    "               subsample = 1)\n",
    "modxgb <- xgb.train(params = params,\n",
    "                    data = dtrain,\n",
    "                    num_class = 6,\n",
    "                    nrounds = 499,\n",
    "                    watchlist = watchlist,\n",
    "                    verbose = 0) # Change this to 1 to watch the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49Wc0nZ4XaY-"
   },
   "source": [
    "the feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4T7hgYsXcm_"
   },
   "outputs": [],
   "source": [
    "# Importance matrix\n",
    "importance_matrix <- xgb.importance(model = modxgb) %>% \n",
    "  mutate(Feature = as.integer(Feature))\n",
    "top10 <- importance_matrix[1:10, ]$Feature\n",
    "top10 <- paste0(\"f\", top10)  # Select top 10 fetures from importance\n",
    "# Names of these features\n",
    "feat_names_10 <- feat_names %>% filter(code %in% top10) %>% \n",
    "  mutate(code = substring(code, 2)) %>%\n",
    "  mutate(code = as.integer(code))\n",
    "reord <- match(feat_names_10$code, importance_matrix[1:10,]$Feature)\n",
    "feat_names_10 %>% dplyr::slice(reord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6pkX8g6XgQP"
   },
   "source": [
    "plot the importance as a function of Gain in trees split when a specific feature is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPZReAaYXiTu"
   },
   "outputs": [],
   "source": [
    "plt.data <- importance_matrix[1:10, ]\n",
    "plt.data$Feature <- feat_names_10 %>% dplyr::slice(reord) %>% dplyr::select(feature)\n",
    "xgb.plot.importance(plt.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpabfmiuXk6O"
   },
   "source": [
    "test the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_CHx5bbXnBO"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred_tst <- predict(modxgb, newdata = dtest)\n",
    "# Reshape in N x n_class\n",
    "pred_matrix <- matrix(pred_tst, nrow = nrow(X_tst), byrow = TRUE) # Reshape for class probs\n",
    "# Accuracy\n",
    "pred_labels <- apply(pred_matrix, 1, which.max)\n",
    "cat(\"Accuracy:\", sum(pred_labels == y_test$label) / length(y_test$label), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFj0kHdGXp6Q"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding and multi-class log loss\n",
    "expanded_tst <- diag(6)\n",
    "expanded_tst <- t(expanded_tst[, y_test$label])\n",
    "cat(\"MLogLoss: \", mlogloss(pred_matrix, expanded_tst), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k02hkSWXs8p"
   },
   "source": [
    "The confusion matrix provides us information on how well we did for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFkwaCwGXvKY"
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "confusionMatrix(pred_labels, y_test$label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5OCViyXXxiR"
   },
   "source": [
    "Gradient Boosting: Linear Booster\n",
    "\n",
    "The hyperparameters determined from 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3ZpI94MX4DX"
   },
   "outputs": [],
   "source": [
    "# Use best model params\n",
    "params <- list(booster = \"gblinear\",\n",
    "               eval_metric = \"mlogloss\",\n",
    "               objective = \"multi:softprob\",\n",
    "               alpha = 0.1,\n",
    "               lambda = 1,\n",
    "               eta = 0.3)\n",
    "modxgb <- xgb.train(params = params,\n",
    "                    data = dtrain,\n",
    "                    num_class = 6,\n",
    "                    nrounds = 497,\n",
    "                    watchlist = watchlist,\n",
    "                    verbose = 0) # Change this to 1 to watch the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Grauo3UCX6CZ"
   },
   "source": [
    "predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPtPBUpQX8R_"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred_tst <- predict(modxgb, newdata = dtest)\n",
    "# Reshape in N x n_class\n",
    "pred_matrix <- matrix(pred_tst, nrow = nrow(X_tst), byrow = TRUE) # Reshape for class probs\n",
    "# Accuracy\n",
    "pred_labels <- apply(pred_matrix, 1, which.max)\n",
    "cat(\"Accuracy:\", sum(pred_labels == y_test$label) / length(y_test$label), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNP8NFayX-si"
   },
   "outputs": [],
   "source": [
    "# Multi-class log loss\n",
    "cat(\"MLogLoss: \", mlogloss(pred_matrix, expanded_tst), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJ5LlAA_YApn"
   },
   "source": [
    "the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOMeJwGTYChf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "confusionMatrix(pred_labels, y_test$label)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SAR_v2_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
